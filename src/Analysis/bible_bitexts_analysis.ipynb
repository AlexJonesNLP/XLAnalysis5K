{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of bible_bitexts_ANALYSIS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8jGjdz1yBM4"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDvC019_vA0e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pingouin as pg\n",
        "import seaborn as sns\n",
        "import scipy.stats\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8mkpqs2yG_8"
      },
      "source": [
        "### Loading dataframes containing variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA_Fgg6dwVrn"
      },
      "source": [
        "# Loading the dataframes we'll be using\n",
        "\n",
        "# Contains the DEPENDENT variables relating to language PAIRS\n",
        "lang_pair_dv = pd.read_csv('/Data/Bible experimental vars/bible_dependent_vars_LANGUAGE_PAIR.csv')\n",
        "\n",
        "# Contains the INDEPENDENT variables relating to language PAIRS\n",
        "lang_pair_iv = pd.read_csv('/Data/bible_predictors_LANGUAGE_PAIR.csv')\n",
        "\n",
        "# Contains ALL variables relating to INDIVIDUAL languages\n",
        "indiv_lang_vars = pd.read_csv('/Data/bible_all_features_LANGUAGE.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI5bYzS4_sVO",
        "outputId": "c085c71a-52b0-4c8d-da38-b98f35127bda"
      },
      "source": [
        "# Tallying zero-shot sub-cases\n",
        "\n",
        "print('Simple zero-shot languages (LaBSE): {}'.format(sum(np.array(indiv_lang_vars['Total sentences (LaBSE)']==0))))\n",
        "print('Simple zero-shot languages (LASER): {}'.format(sum(np.array(indiv_lang_vars['Total sentences (LASER)']==0))))\n",
        "print('Double zero-shot language pairs (LaBSE): {}'.format(sum(np.array(lang_pair_iv['Combined sentences (LaBSE)']==0))))\n",
        "print('Double zero-shot language pairs (LASER): {}'.format(sum(np.array(lang_pair_iv['Combined sentences (LASER)']==0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple zero-shot languages (LaBSE): 35\n",
            "Simple zero-shot languages (LASER): 45\n",
            "Double zero-shot language pairs (LaBSE): 595\n",
            "Double zero-shot language pairs (LASER): 990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-xpYmwjGmZC"
      },
      "source": [
        "# It's pretty helpful to combine the IVs and DVs for language pairs, as Pingouin prefers to work with \n",
        "# single dataframe objects\n",
        "master_pair = pd.concat([lang_pair_iv, lang_pair_dv], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T7Fbblc41OJP",
        "outputId": "940b2ac6-8690-4ce3-df94-c8736659d830"
      },
      "source": [
        "master_pair.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combined sentences (LaBSE)</th>\n",
              "      <th>Combined in-family sentences (LaBSE)</th>\n",
              "      <th>Combined in-genus sentences (LaBSE)</th>\n",
              "      <th>Combined sentences (LASER)</th>\n",
              "      <th>Combined in-family sentences (LASER)</th>\n",
              "      <th>Combined in-genus sentences (LASER)</th>\n",
              "      <th>Same Family?</th>\n",
              "      <th>Same Genus?</th>\n",
              "      <th>Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)</th>\n",
              "      <th>Token-level Overlap (multiset Jaccard coefficient, Book of John)</th>\n",
              "      <th>Same Word Order?</th>\n",
              "      <th>Same Polysynthesis Status?</th>\n",
              "      <th>Geographic Distance (lang2vec)</th>\n",
              "      <th>Inventory Distance (lang2vec)</th>\n",
              "      <th>Syntactic Distance (lang2vec)</th>\n",
              "      <th>Phonological Distance (lang2vec)</th>\n",
              "      <th>F1-score (LaBSE, average)</th>\n",
              "      <th>F1-score (LASER, average)</th>\n",
              "      <th>Gromov-Hausdorff dist. (LaBSE, average)</th>\n",
              "      <th>Gromov-Hausdorff dist. (LASER, average)</th>\n",
              "      <th>Singular value gap (LaBSE, average)</th>\n",
              "      <th>Singular value gap (LASER, average)</th>\n",
              "      <th>ECOND-HM (LaBSE, average)</th>\n",
              "      <th>ECOND-HM (LASER, average)</th>\n",
              "      <th>Average margin score (LaBSE, average)</th>\n",
              "      <th>Average margin score (LASER, average)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Combined sentences (LaBSE)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.319249</td>\n",
              "      <td>0.487660</td>\n",
              "      <td>0.661324</td>\n",
              "      <td>0.316252</td>\n",
              "      <td>0.385381</td>\n",
              "      <td>0.156841</td>\n",
              "      <td>0.057036</td>\n",
              "      <td>-0.098686</td>\n",
              "      <td>0.163112</td>\n",
              "      <td>0.136264</td>\n",
              "      <td>0.176468</td>\n",
              "      <td>-0.128092</td>\n",
              "      <td>0.076060</td>\n",
              "      <td>-0.116656</td>\n",
              "      <td>-0.012324</td>\n",
              "      <td>0.342308</td>\n",
              "      <td>0.319571</td>\n",
              "      <td>-0.133809</td>\n",
              "      <td>-0.140277</td>\n",
              "      <td>-0.076661</td>\n",
              "      <td>-0.094841</td>\n",
              "      <td>-0.033423</td>\n",
              "      <td>-0.073367</td>\n",
              "      <td>0.296391</td>\n",
              "      <td>0.058348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-family sentences (LaBSE)</th>\n",
              "      <td>0.319249</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.801648</td>\n",
              "      <td>0.248638</td>\n",
              "      <td>0.932314</td>\n",
              "      <td>0.568533</td>\n",
              "      <td>0.556810</td>\n",
              "      <td>0.156956</td>\n",
              "      <td>0.083801</td>\n",
              "      <td>0.417382</td>\n",
              "      <td>0.186699</td>\n",
              "      <td>0.267901</td>\n",
              "      <td>-0.361955</td>\n",
              "      <td>-0.078940</td>\n",
              "      <td>-0.410544</td>\n",
              "      <td>-0.352096</td>\n",
              "      <td>0.494691</td>\n",
              "      <td>0.534981</td>\n",
              "      <td>-0.202363</td>\n",
              "      <td>-0.203547</td>\n",
              "      <td>-0.115121</td>\n",
              "      <td>-0.141424</td>\n",
              "      <td>-0.375093</td>\n",
              "      <td>-0.217196</td>\n",
              "      <td>0.396285</td>\n",
              "      <td>0.136211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-genus sentences (LaBSE)</th>\n",
              "      <td>0.487660</td>\n",
              "      <td>0.801648</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.358365</td>\n",
              "      <td>0.820832</td>\n",
              "      <td>0.800504</td>\n",
              "      <td>0.461591</td>\n",
              "      <td>0.190270</td>\n",
              "      <td>0.155000</td>\n",
              "      <td>0.425817</td>\n",
              "      <td>0.156551</td>\n",
              "      <td>0.249691</td>\n",
              "      <td>-0.301913</td>\n",
              "      <td>-0.041288</td>\n",
              "      <td>-0.370486</td>\n",
              "      <td>-0.277699</td>\n",
              "      <td>0.459315</td>\n",
              "      <td>0.526594</td>\n",
              "      <td>-0.177935</td>\n",
              "      <td>-0.184248</td>\n",
              "      <td>-0.107517</td>\n",
              "      <td>-0.133314</td>\n",
              "      <td>-0.306322</td>\n",
              "      <td>-0.237668</td>\n",
              "      <td>0.374820</td>\n",
              "      <td>0.130227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined sentences (LASER)</th>\n",
              "      <td>0.661324</td>\n",
              "      <td>0.248638</td>\n",
              "      <td>0.358365</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.267548</td>\n",
              "      <td>0.480509</td>\n",
              "      <td>0.142106</td>\n",
              "      <td>0.062654</td>\n",
              "      <td>0.111735</td>\n",
              "      <td>0.142176</td>\n",
              "      <td>0.093430</td>\n",
              "      <td>0.075458</td>\n",
              "      <td>-0.109527</td>\n",
              "      <td>0.013959</td>\n",
              "      <td>-0.108658</td>\n",
              "      <td>-0.061852</td>\n",
              "      <td>0.157359</td>\n",
              "      <td>0.128202</td>\n",
              "      <td>-0.064568</td>\n",
              "      <td>-0.068741</td>\n",
              "      <td>-0.032870</td>\n",
              "      <td>-0.041136</td>\n",
              "      <td>0.008450</td>\n",
              "      <td>0.070424</td>\n",
              "      <td>0.162198</td>\n",
              "      <td>-0.026162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-family sentences (LASER)</th>\n",
              "      <td>0.316252</td>\n",
              "      <td>0.932314</td>\n",
              "      <td>0.820832</td>\n",
              "      <td>0.267548</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.610484</td>\n",
              "      <td>0.518565</td>\n",
              "      <td>0.151550</td>\n",
              "      <td>0.181034</td>\n",
              "      <td>0.422686</td>\n",
              "      <td>0.197338</td>\n",
              "      <td>0.241435</td>\n",
              "      <td>-0.358079</td>\n",
              "      <td>-0.072992</td>\n",
              "      <td>-0.427531</td>\n",
              "      <td>-0.343077</td>\n",
              "      <td>0.448157</td>\n",
              "      <td>0.568997</td>\n",
              "      <td>-0.190656</td>\n",
              "      <td>-0.195905</td>\n",
              "      <td>-0.100387</td>\n",
              "      <td>-0.126759</td>\n",
              "      <td>-0.353728</td>\n",
              "      <td>-0.292710</td>\n",
              "      <td>0.362068</td>\n",
              "      <td>0.144876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-genus sentences (LASER)</th>\n",
              "      <td>0.385381</td>\n",
              "      <td>0.568533</td>\n",
              "      <td>0.800504</td>\n",
              "      <td>0.480509</td>\n",
              "      <td>0.610484</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.331247</td>\n",
              "      <td>0.148153</td>\n",
              "      <td>0.230004</td>\n",
              "      <td>0.302854</td>\n",
              "      <td>0.056893</td>\n",
              "      <td>0.153011</td>\n",
              "      <td>-0.211040</td>\n",
              "      <td>0.031153</td>\n",
              "      <td>-0.245886</td>\n",
              "      <td>-0.160460</td>\n",
              "      <td>0.296285</td>\n",
              "      <td>0.347033</td>\n",
              "      <td>-0.084494</td>\n",
              "      <td>-0.097817</td>\n",
              "      <td>-0.065737</td>\n",
              "      <td>-0.082007</td>\n",
              "      <td>-0.210256</td>\n",
              "      <td>-0.112418</td>\n",
              "      <td>0.249414</td>\n",
              "      <td>0.065210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Family?</th>\n",
              "      <td>0.156841</td>\n",
              "      <td>0.556810</td>\n",
              "      <td>0.461591</td>\n",
              "      <td>0.142106</td>\n",
              "      <td>0.518565</td>\n",
              "      <td>0.331247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.464272</td>\n",
              "      <td>0.142928</td>\n",
              "      <td>0.356942</td>\n",
              "      <td>0.204930</td>\n",
              "      <td>0.235862</td>\n",
              "      <td>-0.375254</td>\n",
              "      <td>-0.220503</td>\n",
              "      <td>-0.478111</td>\n",
              "      <td>-0.348164</td>\n",
              "      <td>0.331630</td>\n",
              "      <td>0.459289</td>\n",
              "      <td>-0.138782</td>\n",
              "      <td>-0.126854</td>\n",
              "      <td>-0.044128</td>\n",
              "      <td>-0.056779</td>\n",
              "      <td>-0.199852</td>\n",
              "      <td>-0.109419</td>\n",
              "      <td>0.302019</td>\n",
              "      <td>0.110437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Genus?</th>\n",
              "      <td>0.057036</td>\n",
              "      <td>0.156956</td>\n",
              "      <td>0.190270</td>\n",
              "      <td>0.062654</td>\n",
              "      <td>0.151550</td>\n",
              "      <td>0.148153</td>\n",
              "      <td>0.464272</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.174027</td>\n",
              "      <td>0.206415</td>\n",
              "      <td>0.137293</td>\n",
              "      <td>0.104328</td>\n",
              "      <td>-0.167888</td>\n",
              "      <td>-0.210392</td>\n",
              "      <td>-0.292448</td>\n",
              "      <td>-0.150551</td>\n",
              "      <td>0.129983</td>\n",
              "      <td>0.208714</td>\n",
              "      <td>-0.067563</td>\n",
              "      <td>-0.060175</td>\n",
              "      <td>-0.015971</td>\n",
              "      <td>-0.029778</td>\n",
              "      <td>-0.062283</td>\n",
              "      <td>-0.011053</td>\n",
              "      <td>0.126337</td>\n",
              "      <td>0.040769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)</th>\n",
              "      <td>-0.098686</td>\n",
              "      <td>0.083801</td>\n",
              "      <td>0.155000</td>\n",
              "      <td>0.111735</td>\n",
              "      <td>0.181034</td>\n",
              "      <td>0.230004</td>\n",
              "      <td>0.142928</td>\n",
              "      <td>0.174027</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250565</td>\n",
              "      <td>0.072285</td>\n",
              "      <td>0.030696</td>\n",
              "      <td>-0.077818</td>\n",
              "      <td>-0.236850</td>\n",
              "      <td>-0.149461</td>\n",
              "      <td>-0.073093</td>\n",
              "      <td>0.029063</td>\n",
              "      <td>0.134336</td>\n",
              "      <td>-0.106150</td>\n",
              "      <td>-0.131058</td>\n",
              "      <td>-0.226793</td>\n",
              "      <td>-0.268181</td>\n",
              "      <td>0.097069</td>\n",
              "      <td>0.054790</td>\n",
              "      <td>0.128369</td>\n",
              "      <td>0.044302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Token-level Overlap (multiset Jaccard coefficient, Book of John)</th>\n",
              "      <td>0.163112</td>\n",
              "      <td>0.417382</td>\n",
              "      <td>0.425817</td>\n",
              "      <td>0.142176</td>\n",
              "      <td>0.422686</td>\n",
              "      <td>0.302854</td>\n",
              "      <td>0.356942</td>\n",
              "      <td>0.206415</td>\n",
              "      <td>0.250565</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.210295</td>\n",
              "      <td>0.294600</td>\n",
              "      <td>-0.350034</td>\n",
              "      <td>-0.203511</td>\n",
              "      <td>-0.332701</td>\n",
              "      <td>-0.309709</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>0.480759</td>\n",
              "      <td>-0.068893</td>\n",
              "      <td>-0.041157</td>\n",
              "      <td>-0.073546</td>\n",
              "      <td>-0.040084</td>\n",
              "      <td>-0.070784</td>\n",
              "      <td>-0.106394</td>\n",
              "      <td>0.376943</td>\n",
              "      <td>0.175894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Word Order?</th>\n",
              "      <td>0.136264</td>\n",
              "      <td>0.186699</td>\n",
              "      <td>0.156551</td>\n",
              "      <td>0.093430</td>\n",
              "      <td>0.197338</td>\n",
              "      <td>0.056893</td>\n",
              "      <td>0.204930</td>\n",
              "      <td>0.137293</td>\n",
              "      <td>0.072285</td>\n",
              "      <td>0.210295</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.181624</td>\n",
              "      <td>-0.153082</td>\n",
              "      <td>-0.149434</td>\n",
              "      <td>-0.391336</td>\n",
              "      <td>-0.163951</td>\n",
              "      <td>0.224628</td>\n",
              "      <td>0.325717</td>\n",
              "      <td>-0.180956</td>\n",
              "      <td>-0.183167</td>\n",
              "      <td>-0.071789</td>\n",
              "      <td>-0.040552</td>\n",
              "      <td>-0.042915</td>\n",
              "      <td>-0.088323</td>\n",
              "      <td>0.178767</td>\n",
              "      <td>0.088910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Polysynthesis Status?</th>\n",
              "      <td>0.176468</td>\n",
              "      <td>0.267901</td>\n",
              "      <td>0.249691</td>\n",
              "      <td>0.075458</td>\n",
              "      <td>0.241435</td>\n",
              "      <td>0.153011</td>\n",
              "      <td>0.235862</td>\n",
              "      <td>0.104328</td>\n",
              "      <td>0.030696</td>\n",
              "      <td>0.294600</td>\n",
              "      <td>0.181624</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.490854</td>\n",
              "      <td>-0.209742</td>\n",
              "      <td>-0.169013</td>\n",
              "      <td>-0.244937</td>\n",
              "      <td>0.475923</td>\n",
              "      <td>0.316996</td>\n",
              "      <td>-0.186720</td>\n",
              "      <td>-0.160160</td>\n",
              "      <td>0.047704</td>\n",
              "      <td>0.024045</td>\n",
              "      <td>-0.230066</td>\n",
              "      <td>-0.268770</td>\n",
              "      <td>0.395880</td>\n",
              "      <td>0.080496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geographic Distance (lang2vec)</th>\n",
              "      <td>-0.128092</td>\n",
              "      <td>-0.361955</td>\n",
              "      <td>-0.301913</td>\n",
              "      <td>-0.109527</td>\n",
              "      <td>-0.358079</td>\n",
              "      <td>-0.211040</td>\n",
              "      <td>-0.375254</td>\n",
              "      <td>-0.167888</td>\n",
              "      <td>-0.077818</td>\n",
              "      <td>-0.350034</td>\n",
              "      <td>-0.153082</td>\n",
              "      <td>-0.490854</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.193975</td>\n",
              "      <td>0.360248</td>\n",
              "      <td>0.391729</td>\n",
              "      <td>-0.316011</td>\n",
              "      <td>-0.368386</td>\n",
              "      <td>0.078541</td>\n",
              "      <td>0.054966</td>\n",
              "      <td>-0.077559</td>\n",
              "      <td>-0.076281</td>\n",
              "      <td>0.185833</td>\n",
              "      <td>0.187277</td>\n",
              "      <td>-0.244976</td>\n",
              "      <td>-0.065907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inventory Distance (lang2vec)</th>\n",
              "      <td>0.076060</td>\n",
              "      <td>-0.078940</td>\n",
              "      <td>-0.041288</td>\n",
              "      <td>0.013959</td>\n",
              "      <td>-0.072992</td>\n",
              "      <td>0.031153</td>\n",
              "      <td>-0.220503</td>\n",
              "      <td>-0.210392</td>\n",
              "      <td>-0.236850</td>\n",
              "      <td>-0.203511</td>\n",
              "      <td>-0.149434</td>\n",
              "      <td>-0.209742</td>\n",
              "      <td>0.193975</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.197481</td>\n",
              "      <td>0.338194</td>\n",
              "      <td>-0.155425</td>\n",
              "      <td>-0.158290</td>\n",
              "      <td>0.080342</td>\n",
              "      <td>0.052655</td>\n",
              "      <td>0.094124</td>\n",
              "      <td>0.113939</td>\n",
              "      <td>-0.124443</td>\n",
              "      <td>-0.072731</td>\n",
              "      <td>-0.157944</td>\n",
              "      <td>-0.129462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Syntactic Distance (lang2vec)</th>\n",
              "      <td>-0.116656</td>\n",
              "      <td>-0.410544</td>\n",
              "      <td>-0.370486</td>\n",
              "      <td>-0.108658</td>\n",
              "      <td>-0.427531</td>\n",
              "      <td>-0.245886</td>\n",
              "      <td>-0.478111</td>\n",
              "      <td>-0.292448</td>\n",
              "      <td>-0.149461</td>\n",
              "      <td>-0.332701</td>\n",
              "      <td>-0.391336</td>\n",
              "      <td>-0.169013</td>\n",
              "      <td>0.360248</td>\n",
              "      <td>0.197481</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.330191</td>\n",
              "      <td>-0.263770</td>\n",
              "      <td>-0.442008</td>\n",
              "      <td>0.108413</td>\n",
              "      <td>0.076849</td>\n",
              "      <td>-0.052820</td>\n",
              "      <td>-0.036729</td>\n",
              "      <td>0.173348</td>\n",
              "      <td>0.217952</td>\n",
              "      <td>-0.212883</td>\n",
              "      <td>-0.103503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phonological Distance (lang2vec)</th>\n",
              "      <td>-0.012324</td>\n",
              "      <td>-0.352096</td>\n",
              "      <td>-0.277699</td>\n",
              "      <td>-0.061852</td>\n",
              "      <td>-0.343077</td>\n",
              "      <td>-0.160460</td>\n",
              "      <td>-0.348164</td>\n",
              "      <td>-0.150551</td>\n",
              "      <td>-0.073093</td>\n",
              "      <td>-0.309709</td>\n",
              "      <td>-0.163951</td>\n",
              "      <td>-0.244937</td>\n",
              "      <td>0.391729</td>\n",
              "      <td>0.338194</td>\n",
              "      <td>0.330191</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.209467</td>\n",
              "      <td>-0.273004</td>\n",
              "      <td>0.056043</td>\n",
              "      <td>0.032144</td>\n",
              "      <td>-0.025277</td>\n",
              "      <td>-0.018718</td>\n",
              "      <td>0.154702</td>\n",
              "      <td>0.188167</td>\n",
              "      <td>-0.174878</td>\n",
              "      <td>-0.074109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1-score (LaBSE, average)</th>\n",
              "      <td>0.342308</td>\n",
              "      <td>0.494691</td>\n",
              "      <td>0.459315</td>\n",
              "      <td>0.157359</td>\n",
              "      <td>0.448157</td>\n",
              "      <td>0.296285</td>\n",
              "      <td>0.331630</td>\n",
              "      <td>0.129983</td>\n",
              "      <td>0.029063</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>0.224628</td>\n",
              "      <td>0.475923</td>\n",
              "      <td>-0.316011</td>\n",
              "      <td>-0.155425</td>\n",
              "      <td>-0.263770</td>\n",
              "      <td>-0.209467</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.611783</td>\n",
              "      <td>-0.373403</td>\n",
              "      <td>-0.315665</td>\n",
              "      <td>-0.262722</td>\n",
              "      <td>-0.296341</td>\n",
              "      <td>-0.308747</td>\n",
              "      <td>-0.227229</td>\n",
              "      <td>0.876887</td>\n",
              "      <td>0.201401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1-score (LASER, average)</th>\n",
              "      <td>0.319571</td>\n",
              "      <td>0.534981</td>\n",
              "      <td>0.526594</td>\n",
              "      <td>0.128202</td>\n",
              "      <td>0.568997</td>\n",
              "      <td>0.347033</td>\n",
              "      <td>0.459289</td>\n",
              "      <td>0.208714</td>\n",
              "      <td>0.134336</td>\n",
              "      <td>0.480759</td>\n",
              "      <td>0.325717</td>\n",
              "      <td>0.316996</td>\n",
              "      <td>-0.368386</td>\n",
              "      <td>-0.158290</td>\n",
              "      <td>-0.442008</td>\n",
              "      <td>-0.273004</td>\n",
              "      <td>0.611783</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.245952</td>\n",
              "      <td>-0.239212</td>\n",
              "      <td>-0.116939</td>\n",
              "      <td>-0.144972</td>\n",
              "      <td>-0.274947</td>\n",
              "      <td>-0.324635</td>\n",
              "      <td>0.546377</td>\n",
              "      <td>0.254289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gromov-Hausdorff dist. (LaBSE, average)</th>\n",
              "      <td>-0.133809</td>\n",
              "      <td>-0.202363</td>\n",
              "      <td>-0.177935</td>\n",
              "      <td>-0.064568</td>\n",
              "      <td>-0.190656</td>\n",
              "      <td>-0.084494</td>\n",
              "      <td>-0.138782</td>\n",
              "      <td>-0.067563</td>\n",
              "      <td>-0.106150</td>\n",
              "      <td>-0.068893</td>\n",
              "      <td>-0.180956</td>\n",
              "      <td>-0.186720</td>\n",
              "      <td>0.078541</td>\n",
              "      <td>0.080342</td>\n",
              "      <td>0.108413</td>\n",
              "      <td>0.056043</td>\n",
              "      <td>-0.373403</td>\n",
              "      <td>-0.245952</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959544</td>\n",
              "      <td>0.437095</td>\n",
              "      <td>0.525641</td>\n",
              "      <td>0.091095</td>\n",
              "      <td>0.118580</td>\n",
              "      <td>-0.448881</td>\n",
              "      <td>-0.106735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gromov-Hausdorff dist. (LASER, average)</th>\n",
              "      <td>-0.140277</td>\n",
              "      <td>-0.203547</td>\n",
              "      <td>-0.184248</td>\n",
              "      <td>-0.068741</td>\n",
              "      <td>-0.195905</td>\n",
              "      <td>-0.097817</td>\n",
              "      <td>-0.126854</td>\n",
              "      <td>-0.060175</td>\n",
              "      <td>-0.131058</td>\n",
              "      <td>-0.041157</td>\n",
              "      <td>-0.183167</td>\n",
              "      <td>-0.160160</td>\n",
              "      <td>0.054966</td>\n",
              "      <td>0.052655</td>\n",
              "      <td>0.076849</td>\n",
              "      <td>0.032144</td>\n",
              "      <td>-0.315665</td>\n",
              "      <td>-0.239212</td>\n",
              "      <td>0.959544</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.558484</td>\n",
              "      <td>0.575026</td>\n",
              "      <td>0.067777</td>\n",
              "      <td>0.103162</td>\n",
              "      <td>-0.392504</td>\n",
              "      <td>-0.105455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Singular value gap (LaBSE, average)</th>\n",
              "      <td>-0.076661</td>\n",
              "      <td>-0.115121</td>\n",
              "      <td>-0.107517</td>\n",
              "      <td>-0.032870</td>\n",
              "      <td>-0.100387</td>\n",
              "      <td>-0.065737</td>\n",
              "      <td>-0.044128</td>\n",
              "      <td>-0.015971</td>\n",
              "      <td>-0.226793</td>\n",
              "      <td>-0.073546</td>\n",
              "      <td>-0.071789</td>\n",
              "      <td>0.047704</td>\n",
              "      <td>-0.077559</td>\n",
              "      <td>0.094124</td>\n",
              "      <td>-0.052820</td>\n",
              "      <td>-0.025277</td>\n",
              "      <td>-0.262722</td>\n",
              "      <td>-0.116939</td>\n",
              "      <td>0.437095</td>\n",
              "      <td>0.558484</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.818843</td>\n",
              "      <td>-0.348419</td>\n",
              "      <td>-0.326498</td>\n",
              "      <td>-0.351131</td>\n",
              "      <td>-0.173531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Singular value gap (LASER, average)</th>\n",
              "      <td>-0.094841</td>\n",
              "      <td>-0.141424</td>\n",
              "      <td>-0.133314</td>\n",
              "      <td>-0.041136</td>\n",
              "      <td>-0.126759</td>\n",
              "      <td>-0.082007</td>\n",
              "      <td>-0.056779</td>\n",
              "      <td>-0.029778</td>\n",
              "      <td>-0.268181</td>\n",
              "      <td>-0.040084</td>\n",
              "      <td>-0.040552</td>\n",
              "      <td>0.024045</td>\n",
              "      <td>-0.076281</td>\n",
              "      <td>0.113939</td>\n",
              "      <td>-0.036729</td>\n",
              "      <td>-0.018718</td>\n",
              "      <td>-0.296341</td>\n",
              "      <td>-0.144972</td>\n",
              "      <td>0.525641</td>\n",
              "      <td>0.575026</td>\n",
              "      <td>0.818843</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.233892</td>\n",
              "      <td>-0.288052</td>\n",
              "      <td>-0.470780</td>\n",
              "      <td>-0.152813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ECOND-HM (LaBSE, average)</th>\n",
              "      <td>-0.033423</td>\n",
              "      <td>-0.375093</td>\n",
              "      <td>-0.306322</td>\n",
              "      <td>0.008450</td>\n",
              "      <td>-0.353728</td>\n",
              "      <td>-0.210256</td>\n",
              "      <td>-0.199852</td>\n",
              "      <td>-0.062283</td>\n",
              "      <td>0.097069</td>\n",
              "      <td>-0.070784</td>\n",
              "      <td>-0.042915</td>\n",
              "      <td>-0.230066</td>\n",
              "      <td>0.185833</td>\n",
              "      <td>-0.124443</td>\n",
              "      <td>0.173348</td>\n",
              "      <td>0.154702</td>\n",
              "      <td>-0.308747</td>\n",
              "      <td>-0.274947</td>\n",
              "      <td>0.091095</td>\n",
              "      <td>0.067777</td>\n",
              "      <td>-0.348419</td>\n",
              "      <td>-0.233892</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.543260</td>\n",
              "      <td>-0.241220</td>\n",
              "      <td>0.148031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ECOND-HM (LASER, average)</th>\n",
              "      <td>-0.073367</td>\n",
              "      <td>-0.217196</td>\n",
              "      <td>-0.237668</td>\n",
              "      <td>0.070424</td>\n",
              "      <td>-0.292710</td>\n",
              "      <td>-0.112418</td>\n",
              "      <td>-0.109419</td>\n",
              "      <td>-0.011053</td>\n",
              "      <td>0.054790</td>\n",
              "      <td>-0.106394</td>\n",
              "      <td>-0.088323</td>\n",
              "      <td>-0.268770</td>\n",
              "      <td>0.187277</td>\n",
              "      <td>-0.072731</td>\n",
              "      <td>0.217952</td>\n",
              "      <td>0.188167</td>\n",
              "      <td>-0.227229</td>\n",
              "      <td>-0.324635</td>\n",
              "      <td>0.118580</td>\n",
              "      <td>0.103162</td>\n",
              "      <td>-0.326498</td>\n",
              "      <td>-0.288052</td>\n",
              "      <td>0.543260</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.147500</td>\n",
              "      <td>-0.038515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average margin score (LaBSE, average)</th>\n",
              "      <td>0.296391</td>\n",
              "      <td>0.396285</td>\n",
              "      <td>0.374820</td>\n",
              "      <td>0.162198</td>\n",
              "      <td>0.362068</td>\n",
              "      <td>0.249414</td>\n",
              "      <td>0.302019</td>\n",
              "      <td>0.126337</td>\n",
              "      <td>0.128369</td>\n",
              "      <td>0.376943</td>\n",
              "      <td>0.178767</td>\n",
              "      <td>0.395880</td>\n",
              "      <td>-0.244976</td>\n",
              "      <td>-0.157944</td>\n",
              "      <td>-0.212883</td>\n",
              "      <td>-0.174878</td>\n",
              "      <td>0.876887</td>\n",
              "      <td>0.546377</td>\n",
              "      <td>-0.448881</td>\n",
              "      <td>-0.392504</td>\n",
              "      <td>-0.351131</td>\n",
              "      <td>-0.470780</td>\n",
              "      <td>-0.241220</td>\n",
              "      <td>-0.147500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.158071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average margin score (LASER, average)</th>\n",
              "      <td>0.058348</td>\n",
              "      <td>0.136211</td>\n",
              "      <td>0.130227</td>\n",
              "      <td>-0.026162</td>\n",
              "      <td>0.144876</td>\n",
              "      <td>0.065210</td>\n",
              "      <td>0.110437</td>\n",
              "      <td>0.040769</td>\n",
              "      <td>0.044302</td>\n",
              "      <td>0.175894</td>\n",
              "      <td>0.088910</td>\n",
              "      <td>0.080496</td>\n",
              "      <td>-0.065907</td>\n",
              "      <td>-0.129462</td>\n",
              "      <td>-0.103503</td>\n",
              "      <td>-0.074109</td>\n",
              "      <td>0.201401</td>\n",
              "      <td>0.254289</td>\n",
              "      <td>-0.106735</td>\n",
              "      <td>-0.105455</td>\n",
              "      <td>-0.173531</td>\n",
              "      <td>-0.152813</td>\n",
              "      <td>0.148031</td>\n",
              "      <td>-0.038515</td>\n",
              "      <td>0.158071</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Combined sentences (LaBSE)  ...  Average margin score (LASER, average)\n",
              "Combined sentences (LaBSE)                                            1.000000  ...                               0.058348\n",
              "Combined in-family sentences (LaBSE)                                  0.319249  ...                               0.136211\n",
              "Combined in-genus sentences (LaBSE)                                   0.487660  ...                               0.130227\n",
              "Combined sentences (LASER)                                            0.661324  ...                              -0.026162\n",
              "Combined in-family sentences (LASER)                                  0.316252  ...                               0.144876\n",
              "Combined in-genus sentences (LASER)                                   0.385381  ...                               0.065210\n",
              "Same Family?                                                          0.156841  ...                               0.110437\n",
              "Same Genus?                                                           0.057036  ...                               0.040769\n",
              "Character-level Overlap (multiset Jaccard coeff...                   -0.098686  ...                               0.044302\n",
              "Token-level Overlap (multiset Jaccard coefficie...                    0.163112  ...                               0.175894\n",
              "Same Word Order?                                                      0.136264  ...                               0.088910\n",
              "Same Polysynthesis Status?                                            0.176468  ...                               0.080496\n",
              "Geographic Distance (lang2vec)                                       -0.128092  ...                              -0.065907\n",
              "Inventory Distance (lang2vec)                                         0.076060  ...                              -0.129462\n",
              "Syntactic Distance (lang2vec)                                        -0.116656  ...                              -0.103503\n",
              "Phonological Distance (lang2vec)                                     -0.012324  ...                              -0.074109\n",
              "F1-score (LaBSE, average)                                             0.342308  ...                               0.201401\n",
              "F1-score (LASER, average)                                             0.319571  ...                               0.254289\n",
              "Gromov-Hausdorff dist. (LaBSE, average)                              -0.133809  ...                              -0.106735\n",
              "Gromov-Hausdorff dist. (LASER, average)                              -0.140277  ...                              -0.105455\n",
              "Singular value gap (LaBSE, average)                                  -0.076661  ...                              -0.173531\n",
              "Singular value gap (LASER, average)                                  -0.094841  ...                              -0.152813\n",
              "ECOND-HM (LaBSE, average)                                            -0.033423  ...                               0.148031\n",
              "ECOND-HM (LASER, average)                                            -0.073367  ...                              -0.038515\n",
              "Average margin score (LaBSE, average)                                 0.296391  ...                               0.158071\n",
              "Average margin score (LASER, average)                                 0.058348  ...                               1.000000\n",
              "\n",
              "[26 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nbsxvx78x838",
        "outputId": "075f0ba4-96cf-480c-a435-a806c8feb5f8"
      },
      "source": [
        "pg.ancova(data=master_pair, \n",
        "          dv='F1-score (LASER, average)', \n",
        "          between='Same Genus?',\n",
        "          covar=['Combined sentences (LASER)', \n",
        "                 'Combined in-family sentences (LASER)',\n",
        "                 'Combined in-genus sentences (LASER)'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>SS</th>\n",
              "      <th>DF</th>\n",
              "      <th>F</th>\n",
              "      <th>p-unc</th>\n",
              "      <th>np2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Same Genus?</td>\n",
              "      <td>2.741650</td>\n",
              "      <td>1</td>\n",
              "      <td>117.647836</td>\n",
              "      <td>4.115628e-27</td>\n",
              "      <td>0.022788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combined sentences (LASER)</td>\n",
              "      <td>0.123803</td>\n",
              "      <td>1</td>\n",
              "      <td>5.312566</td>\n",
              "      <td>2.121256e-02</td>\n",
              "      <td>0.001052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Combined in-family sentences (LASER)</td>\n",
              "      <td>34.260927</td>\n",
              "      <td>1</td>\n",
              "      <td>1470.181837</td>\n",
              "      <td>1.625824e-282</td>\n",
              "      <td>0.225655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Combined in-genus sentences (LASER)</td>\n",
              "      <td>0.001143</td>\n",
              "      <td>1</td>\n",
              "      <td>0.049039</td>\n",
              "      <td>8.247530e-01</td>\n",
              "      <td>0.000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Residual</td>\n",
              "      <td>117.568026</td>\n",
              "      <td>5045</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Source          SS  ...          p-unc       np2\n",
              "0                           Same Genus?    2.741650  ...   4.115628e-27  0.022788\n",
              "1            Combined sentences (LASER)    0.123803  ...   2.121256e-02  0.001052\n",
              "2  Combined in-family sentences (LASER)   34.260927  ...  1.625824e-282  0.225655\n",
              "3   Combined in-genus sentences (LASER)    0.001143  ...   8.247530e-01  0.000010\n",
              "4                              Residual  117.568026  ...            NaN       NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "6NlNI0kLGnG-",
        "outputId": "79941127-4a85-4210-fff8-ced79845861e"
      },
      "source": [
        "pg.partial_corr(data=master_pair,\n",
        "                x='Phonological Distance (lang2vec)',\n",
        "                y='Average margin score (LASER, average)',\n",
        "                covar=['Combined sentences (LASER)',\n",
        "                       'Combined in-family sentences (LASER)',\n",
        "                       'Combined in-genus sentences (LASER)'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>r</th>\n",
              "      <th>CI95%</th>\n",
              "      <th>r2</th>\n",
              "      <th>adj_r2</th>\n",
              "      <th>p-val</th>\n",
              "      <th>BF10</th>\n",
              "      <th>power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pearson</th>\n",
              "      <td>5050</td>\n",
              "      <td>-0.024031</td>\n",
              "      <td>[-0.05, 0.0]</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.087726</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.400525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            n         r         CI95%  ...     p-val   BF10     power\n",
              "pearson  5050 -0.024031  [-0.05, 0.0]  ...  0.087726  0.076  0.400525\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0j-CnbTtDGR"
      },
      "source": [
        "double_zero_shot_labse = master_pair[np.array(master_pair['Combined sentences (LaBSE)'])==0]\n",
        "double_zero_shot_laser = master_pair[np.array(master_pair['Combined sentences (LASER)'])==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYLebQ_vwxsF",
        "outputId": "c97ef60a-2938-4f0b-dc08-481a35292bc3"
      },
      "source": [
        "double_zero_shot_labse['Gromov-Hausdorff dist. (LaBSE, average)'] = -double_zero_shot_labse['Gromov-Hausdorff dist. (LaBSE, average)']\n",
        "double_zero_shot_labse['Gromov-Hausdorff dist. (LASER, average)'] = -double_zero_shot_laser['Gromov-Hausdorff dist. (LASER, average)']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34VEQ4WLw67Y",
        "outputId": "92415744-b63c-47c7-8b42-b86bcad7c69d"
      },
      "source": [
        "double_zero_shot_labse['Singular value gap (LaBSE, average)'] = -double_zero_shot_labse['Singular value gap (LaBSE, average)']\n",
        "double_zero_shot_laser['Singular value gap (LASER, average)'] = -double_zero_shot_laser['Singular value gap (LASER, average)']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o46TRPaGvk_D"
      },
      "source": [
        "double_zero_shot_labse = double_zero_shot_labse[['Same Family?', 'Same Genus?', \n",
        "                                                 'Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)',\n",
        "                                                 'Token-level Overlap (multiset Jaccard coefficient, Book of John)',\n",
        "                                                 'Same Word Order?', 'Same Polysynthesis Status?',\t'Geographic Distance (lang2vec)',\n",
        "                                                 'Inventory Distance (lang2vec)',\t'Syntactic Distance (lang2vec)',\n",
        "                                                 'Phonological Distance (lang2vec)', 'F1-score (LaBSE, average)',\t\n",
        "                                                 'Gromov-Hausdorff dist. (LaBSE, average)',\n",
        "                                                 'Singular value gap (LaBSE, average)',\n",
        "                                                 'ECOND-HM (LaBSE, average)',\n",
        "                                                 'Average margin score (LaBSE, average)', 'Language pair']]\n",
        "\n",
        "double_zero_shot_laser = double_zero_shot_laser[['Same Family?', 'Same Genus?', \n",
        "                                                 'Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)',\n",
        "                                                 'Token-level Overlap (multiset Jaccard coefficient, Book of John)',\n",
        "                                                 'Same Word Order?', 'Same Polysynthesis Status?',\t'Geographic Distance (lang2vec)',\n",
        "                                                 'Inventory Distance (lang2vec)',\t'Syntactic Distance (lang2vec)',\n",
        "                                                 'Phonological Distance (lang2vec)', 'F1-score (LASER, average)',\t\n",
        "                                                 'Gromov-Hausdorff dist. (LASER, average)',\n",
        "                                                 'Singular value gap (LASER, average)',\n",
        "                                                 'ECOND-HM (LASER, average)',\n",
        "                                                 'Average margin score (LASER, average)', 'Language pair']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHcLN9rMChFN"
      },
      "source": [
        "print(pg.anova(data=double_zero_shot_labse, dv='F1-score (LaBSE, average)', between='Same Word Order?'))\n",
        "print(pg.anova(data=double_zero_shot_labse, dv='F1-score (LaBSE, average)', between='Same Polysynthesis Status?'))\n",
        "print(pg.anova(data=double_zero_shot_labse, dv='F1-score (LaBSE, average)', between='Same Family?'))\n",
        "print(pg.anova(data=double_zero_shot_labse, dv='F1-score (LaBSE, average)', between='Same Genus?'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6pdWgCZrrJ2"
      },
      "source": [
        "print(scipy.stats.pearsonr(double_zero_shot_labse['F1-score (LaBSE, average)'], \n",
        "                     double_zero_shot_labse['Syntactic Distance (lang2vec)']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFfjEsm8utQH"
      },
      "source": [
        "def corrUtilIO(corr: tuple, s1:str, s2:str):\n",
        "  r, p = corr\n",
        "  out = 'Correlation between {} and {}: {} | p-value: {}'.format(s1, s2, r, p)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRMPbrVMs1e_",
        "outputId": "09bd15df-703e-4eb5-a1f4-2d63d007a6b6"
      },
      "source": [
        "print('Examining double-zero shot language pairs (LaBSE)')\n",
        "print('--------------------------------------------------')\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_labse['F1-score (LaBSE, average)'], \n",
        "                                      double_zero_shot_labse['Inventory Distance (lang2vec)']), \n",
        "                                      'F1-score', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_labse['Gromov-Hausdorff dist. (LaBSE, average)'], \n",
        "                                      double_zero_shot_labse['Inventory Distance (lang2vec)']), \n",
        "                                      'Gromov-Hausdorff distance', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_labse['Singular value gap (LaBSE, average)'], \n",
        "                                      double_zero_shot_labse['Inventory Distance (lang2vec)']), \n",
        "                                      'singular value gap', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_labse['ECOND-HM (LaBSE, average)'], \n",
        "                                      double_zero_shot_labse['Inventory Distance (lang2vec)']), \n",
        "                                      'ECOND-HM', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_labse['Average margin score (LaBSE, average)'], \n",
        "                                      double_zero_shot_labse['Inventory Distance (lang2vec)']), \n",
        "                                      'average margin score', 'inventory distance'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Examining double-zero shot language pairs (LaBSE)\n",
            "--------------------------------------------------\n",
            "Correlation between F1-score and inventory distance: -0.33724823383287633 | p-value: 2.7175319027258977e-17\n",
            "Correlation between Gromov-Hausdorff distance and inventory distance: -0.0686797479579177 | p-value: 0.09418309896867325\n",
            "Correlation between singular value gap and inventory distance: -0.2207380504269484 | p-value: 5.31897763102463e-08\n",
            "Correlation between ECOND-HM and inventory distance: -0.3930150872874848 | p-value: 2.0514426878687908e-23\n",
            "Correlation between average margin score and inventory distance: -0.3048283011613173 | p-value: 2.925467934356142e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYlAhjSn1u5s"
      },
      "source": [
        "X_to_regress_1 = ['Inventory Distance (lang2vec)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
        "X_to_regress_2 = ['Inventory Distance (lang2vec)', 'Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "5DTKX6c34Cuo",
        "outputId": "15804ca0-87e2-4ccb-c36e-f2c0026ea4db"
      },
      "source": [
        "pg.linear_regression(X=double_zero_shot_labse[X_to_regress_2], y=double_zero_shot_labse['F1-score (LaBSE, average)'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>names</th>\n",
              "      <th>coef</th>\n",
              "      <th>se</th>\n",
              "      <th>T</th>\n",
              "      <th>pval</th>\n",
              "      <th>r2</th>\n",
              "      <th>adj_r2</th>\n",
              "      <th>CI[2.5%]</th>\n",
              "      <th>CI[97.5%]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intercept</td>\n",
              "      <td>0.091118</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>9.136109</td>\n",
              "      <td>1.020272e-18</td>\n",
              "      <td>0.439698</td>\n",
              "      <td>0.437805</td>\n",
              "      <td>0.071530</td>\n",
              "      <td>0.110705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Inventory Distance (lang2vec)</td>\n",
              "      <td>-0.195481</td>\n",
              "      <td>0.028141</td>\n",
              "      <td>-6.946500</td>\n",
              "      <td>9.895264e-12</td>\n",
              "      <td>0.439698</td>\n",
              "      <td>0.437805</td>\n",
              "      <td>-0.250749</td>\n",
              "      <td>-0.140213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Character-level Overlap (multiset Jaccard coef...</td>\n",
              "      <td>0.243819</td>\n",
              "      <td>0.013138</td>\n",
              "      <td>18.558068</td>\n",
              "      <td>6.108553e-61</td>\n",
              "      <td>0.439698</td>\n",
              "      <td>0.437805</td>\n",
              "      <td>0.218016</td>\n",
              "      <td>0.269622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               names  ...  CI[97.5%]\n",
              "0                                          Intercept  ...   0.110705\n",
              "1                      Inventory Distance (lang2vec)  ...  -0.140213\n",
              "2  Character-level Overlap (multiset Jaccard coef...  ...   0.269622\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX7AtnhfxWXM",
        "outputId": "183baf1f-6070-4c91-d243-e7a5ea8dd678"
      },
      "source": [
        "print('Examining double-zero shot language pairs (LASER)')\n",
        "print('--------------------------------------------------')\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_laser['F1-score (LASER, average)'], \n",
        "                                      double_zero_shot_laser['Inventory Distance (lang2vec)']), \n",
        "                                      'F1-score', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_laser['Gromov-Hausdorff dist. (LASER, average)'], \n",
        "                                      double_zero_shot_laser['Inventory Distance (lang2vec)']), \n",
        "                                      'Gromov-Hausdorff distance', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_laser['Singular value gap (LASER, average)'], \n",
        "                                      double_zero_shot_laser['Inventory Distance (lang2vec)']), \n",
        "                                      'singular value gap', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_laser['ECOND-HM (LASER, average)'], \n",
        "                                      double_zero_shot_laser['Inventory Distance (lang2vec)']), \n",
        "                                      'ECOND-HM', 'inventory distance'))\n",
        "print(corrUtilIO(scipy.stats.pearsonr(double_zero_shot_laser['Average margin score (LASER, average)'], \n",
        "                                      double_zero_shot_laser['Inventory Distance (lang2vec)']), \n",
        "                                      'average margin score', 'inventory distance'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Examining double-zero shot language pairs (LASER)\n",
            "--------------------------------------------------\n",
            "Correlation between F1-score and inventory distance: -0.127669949469008 | p-value: 5.6142950992676594e-05\n",
            "Correlation between Gromov-Hausdorff distance and inventory distance: 0.050291835337428856 | p-value: 0.11378722704645745\n",
            "Correlation between singular value gap and inventory distance: -0.07911088506905038 | p-value: 0.012777024986595574\n",
            "Correlation between ECOND-HM and inventory distance: 0.1440475335405774 | p-value: 5.355038479530176e-06\n",
            "Correlation between average margin score and inventory distance: -0.09227268163614558 | p-value: 0.0036628574255727206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f62CR3nLKY8n"
      },
      "source": [
        "simple_zero_shot_labse = indiv_lang_vars[np.array(indiv_lang_vars['Total sentences (LaBSE)'])==0]\n",
        "simple_zero_shot_laser = indiv_lang_vars[np.array(indiv_lang_vars['Total sentences (LASER)'])==0]\n",
        "\n",
        "simple_zero_shot_labse = simple_zero_shot_labse.drop(['Total sentences (LaBSE)', 'Total in-family sentences (LaBSE)', \n",
        "                             'Total in-genus sentences (LaBSE)', 'Total sentences (LASER)', \n",
        "                             'Total in-family sentences (LASER)', 'Total in-genus sentences (LASER)',\n",
        "                             'Average F1 (LASER)', 'Average G-H dist. (LASER)', 'Average SVG (LASER)',\n",
        "                             'Average ECOND-HM (LASER)', 'Grand mean margin score (LASER)'], axis=1)\n",
        "\n",
        "simple_zero_shot_laser = simple_zero_shot_laser.drop(['Total sentences (LaBSE)', 'Total in-family sentences (LaBSE)', \n",
        "                             'Total in-genus sentences (LaBSE)', 'Total sentences (LASER)', \n",
        "                             'Total in-family sentences (LASER)', 'Total in-genus sentences (LASER)',\n",
        "                             'Average F1 (LaBSE)', 'Average G-H dist. (LaBSE)', 'Average SVG (LaBSE)',\n",
        "                             'Average ECOND-HM (LaBSE)', 'Grand mean margin score (LaBSE)'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLonJI_YLnu5",
        "outputId": "184865ef-ca8b-4e57-95d4-7fb746aa31f2"
      },
      "source": [
        "print('Running ANOVAs to check for omnibus group mean differences in the DVs for basic word order')\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average F1 (LaBSE)', between='Basic Word Order', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average G-H dist. (LaBSE)', between='Basic Word Order', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average SVG (LaBSE)', between='Basic Word Order', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average ECOND-HM (LaBSE)', between='Basic Word Order', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Grand mean margin score (LaBSE)', between='Basic Word Order', ss_type=3))\n",
        "print('\\n')\n",
        "print('Running ANOVAs to check for omnibus group mean differences in the DVs for polysyntheticity')\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average F1 (LaBSE)', between='Polysynthetic?', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average G-H dist. (LaBSE)', between='Polysynthetic?', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average SVG (LaBSE)', between='Polysynthetic?', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average ECOND-HM (LaBSE)', between='Polysynthetic?', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Grand mean margin score (LaBSE)', between='Polysynthetic?', ss_type=3))\n",
        "print('\\n')\n",
        "print('Running ANOVAs to check for omnibus group mean differences in the DVs for family')\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average F1 (LaBSE)', between='Family', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average G-H dist. (LaBSE)', between='Family', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average SVG (LaBSE)', between='Family', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average ECOND-HM (LaBSE)', between='Family', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Grand mean margin score (LaBSE)', between='Family', ss_type=3))\n",
        "print('\\n')\n",
        "print('Running ANOVAs to check for omnibus group mean differences in the DVs for genus')\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average F1 (LaBSE)', between='Genus', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average G-H dist. (LaBSE)', between='Genus', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average SVG (LaBSE)', between='Genus', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average ECOND-HM (LaBSE)', between='Genus', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Grand mean margin score (LaBSE)', between='Genus', ss_type=3))\n",
        "print('\\n')\n",
        "print('Running ANOVAs to check for omnibus group mean differences in the DVs for script')\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average F1 (LaBSE)', between='Script', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average G-H dist. (LaBSE)', between='Script', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average SVG (LaBSE)', between='Script', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Average ECOND-HM (LaBSE)', between='Script', ss_type=3))\n",
        "print(pg.anova(data=simple_zero_shot_labse, dv='Grand mean margin score (LaBSE)', between='Script', ss_type=3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running ANOVAs to check for omnibus group mean differences in the DVs for basic word order\n",
            "             Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Basic Word Order      7     27  2.198701  0.066555  0.363071\n",
            "             Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Basic Word Order      7     27  1.396682  0.247187  0.265841\n",
            "             Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Basic Word Order      7     27  0.450401  0.861108  0.104561\n",
            "             Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Basic Word Order      7     27  2.199274  0.066492  0.363131\n",
            "             Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Basic Word Order      7     27  1.715491  0.147461  0.307842\n",
            "\n",
            "\n",
            "Running ANOVAs to check for omnibus group mean differences in the DVs for polysyntheticity\n",
            "           Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Polysynthetic?      1     33  0.220212  0.641964  0.006629\n",
            "           Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Polysynthetic?      1     33  2.030424  0.163567  0.057962\n",
            "           Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Polysynthetic?      1     33  1.376524  0.249093  0.040043\n",
            "           Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Polysynthetic?      1     33  0.220054  0.642084  0.006624\n",
            "           Source  ddof1  ddof2         F     p-unc      np2\n",
            "0  Polysynthetic?      1     33  0.636075  0.430837  0.01891\n",
            "\n",
            "\n",
            "Running ANOVAs to check for omnibus group mean differences in the DVs for family\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Family     19     15  1.421432  0.247139  0.642918\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Family     19     15  2.388181  0.046171  0.751555\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Family     19     15  0.204183  0.999226  0.205486\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Family     19     15  1.421729  0.247009  0.642966\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Family     19     15  1.968022  0.093944  0.713699\n",
            "\n",
            "\n",
            "Running ANOVAs to check for omnibus group mean differences in the DVs for genus\n",
            "  Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Genus     27      7  1.662188  0.250874  0.865071\n",
            "  Source  ddof1  ddof2          F     p-unc       np2\n",
            "0  Genus     27      7  14.154914  0.000689  0.982014\n",
            "  Source  ddof1  ddof2              F         p-unc       np2\n",
            "0  Genus     27      7  231758.080717  1.556980e-18  0.999999\n",
            "  Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Genus     27      7  1.662553  0.250771  0.865096\n",
            "  Source  ddof1  ddof2        F     p-unc       np2\n",
            "0  Genus     27      7  4.19455  0.028288  0.941789\n",
            "\n",
            "\n",
            "Running ANOVAs to check for omnibus group mean differences in the DVs for script\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Script      4     30  1.646355  0.188539  0.180001\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Script      4     30  1.505646  0.225546  0.167189\n",
            "   Source  ddof1  ddof2           F         p-unc     np2\n",
            "0  Script      4     30  149.732352  2.301662e-19  0.9523\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Script      4     30  1.646298  0.188553  0.179996\n",
            "   Source  ddof1  ddof2         F     p-unc       np2\n",
            "0  Script      4     30  2.587595  0.056838  0.256513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "M2lPW2QvXsJm",
        "outputId": "89616de7-9e11-4d41-fe61-aecf1e426ce8"
      },
      "source": [
        "sns.barplot(simple_zero_shot_labse['Basic Word Order'], simple_zero_shot_labse['Average F1 (LaBSE)'])\n",
        "plt.ylabel('Meta-average F1 (LaBSE), zero-shot only', fontsize=12)\n",
        "plt.xlabel('Basic word order', fontsize=14)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Basic word order')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "7y5LHn5b0CkZ",
        "outputId": "e861e296-b5f1-4877-904a-ea59abd775f5"
      },
      "source": [
        "sns.barplot(simple_zero_shot_laser['Basic Word Order'], simple_zero_shot_laser['Average F1 (LASER)'])\n",
        "plt.ylabel('Meta-average F1 (LASER), zero-shot only', fontsize=12)\n",
        "plt.xlabel('Basic word order', fontsize=14)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Basic word order')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "2L17gDPHZoN_",
        "outputId": "f26249a8-e021-43cf-f821-3ba0b81ba245"
      },
      "source": [
        "sns.barplot(simple_zero_shot_labse['Basic Word Order'], simple_zero_shot_labse['Average ECOND-HM (LaBSE)'])\n",
        "plt.ylabel('Meta-average ECOND-HM (LaBSE), zero-shot only', fontsize=11)\n",
        "plt.xlabel('Basic word order', fontsize=14)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Basic word order')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "id": "5-SnXQUA32LT",
        "outputId": "df301e2a-28c0-44ed-b140-c1a4768bba16"
      },
      "source": [
        "pg.pairwise_tukey(data=simple_zero_shot_labse, dv='Average F1 (LaBSE)', between='Basic Word Order')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>mean(A)</th>\n",
              "      <th>mean(B)</th>\n",
              "      <th>diff</th>\n",
              "      <th>se</th>\n",
              "      <th>T</th>\n",
              "      <th>p-tukey</th>\n",
              "      <th>hedges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>OSV</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.437189</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.288470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>OVS</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.158700</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>1.110112</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.732484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>SOV</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.162290</td>\n",
              "      <td>0.084710</td>\n",
              "      <td>0.081499</td>\n",
              "      <td>1.039400</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.636481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>0.138986</td>\n",
              "      <td>0.085434</td>\n",
              "      <td>1.626818</td>\n",
              "      <td>0.705843</td>\n",
              "      <td>1.013971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>-0.095000</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.664528</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.438475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.090500</td>\n",
              "      <td>0.101087</td>\n",
              "      <td>0.895268</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.584787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.308444</td>\n",
              "      <td>-0.061444</td>\n",
              "      <td>0.082537</td>\n",
              "      <td>-0.744446</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.458120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OSV</td>\n",
              "      <td>OVS</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.221200</td>\n",
              "      <td>0.175088</td>\n",
              "      <td>1.263366</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>7.146677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>OSV</td>\n",
              "      <td>SOV</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.162290</td>\n",
              "      <td>0.147210</td>\n",
              "      <td>0.129849</td>\n",
              "      <td>1.133705</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>1.087122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>OSV</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>0.201486</td>\n",
              "      <td>0.132354</td>\n",
              "      <td>1.522325</td>\n",
              "      <td>0.763571</td>\n",
              "      <td>1.415160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>OSV</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>-0.032500</td>\n",
              "      <td>0.175088</td>\n",
              "      <td>-0.185621</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-1.050032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>OSV</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.153000</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>1.070240</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.706175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>OSV</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.308444</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>0.130503</td>\n",
              "      <td>0.008088</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.007701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>OVS</td>\n",
              "      <td>SOV</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.162290</td>\n",
              "      <td>-0.073990</td>\n",
              "      <td>0.129849</td>\n",
              "      <td>-0.569817</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.546404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>OVS</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>-0.019714</td>\n",
              "      <td>0.132354</td>\n",
              "      <td>-0.148951</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.138466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>OVS</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>-0.253700</td>\n",
              "      <td>0.175088</td>\n",
              "      <td>-1.448987</td>\n",
              "      <td>0.804082</td>\n",
              "      <td>-8.196709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>OVS</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>-0.068200</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>-0.477061</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.314779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>OVS</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.308444</td>\n",
              "      <td>-0.220144</td>\n",
              "      <td>0.130503</td>\n",
              "      <td>-1.686895</td>\n",
              "      <td>0.672651</td>\n",
              "      <td>-1.606065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SOV</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.162290</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>0.054276</td>\n",
              "      <td>0.061012</td>\n",
              "      <td>0.889588</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.416103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SOV</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.162290</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>-0.179710</td>\n",
              "      <td>0.129849</td>\n",
              "      <td>-1.383996</td>\n",
              "      <td>0.839988</td>\n",
              "      <td>-1.327129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>SOV</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.162290</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.005790</td>\n",
              "      <td>0.081499</td>\n",
              "      <td>0.071044</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.043504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>SOV</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.162290</td>\n",
              "      <td>0.308444</td>\n",
              "      <td>-0.146154</td>\n",
              "      <td>0.056885</td>\n",
              "      <td>-2.569304</td>\n",
              "      <td>0.210563</td>\n",
              "      <td>-1.127655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>SVO</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>-0.233986</td>\n",
              "      <td>0.132354</td>\n",
              "      <td>-1.767879</td>\n",
              "      <td>0.627914</td>\n",
              "      <td>-1.643428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>SVO</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>-0.048486</td>\n",
              "      <td>0.085434</td>\n",
              "      <td>-0.567522</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.353728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>SVO</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>0.308444</td>\n",
              "      <td>-0.200430</td>\n",
              "      <td>0.062392</td>\n",
              "      <td>-3.212421</td>\n",
              "      <td>0.058051</td>\n",
              "      <td>-1.530604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Unknown</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.185500</td>\n",
              "      <td>0.142959</td>\n",
              "      <td>1.297578</td>\n",
              "      <td>0.887728</td>\n",
              "      <td>0.856180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unknown</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>0.308444</td>\n",
              "      <td>0.033556</td>\n",
              "      <td>0.130503</td>\n",
              "      <td>0.257125</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.244805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>VOS</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.308444</td>\n",
              "      <td>-0.151944</td>\n",
              "      <td>0.082537</td>\n",
              "      <td>-1.840921</td>\n",
              "      <td>0.587561</td>\n",
              "      <td>-1.132874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          A        B   mean(A)  ...         T   p-tukey    hedges\n",
              "0     Mixed      OSV  0.247000  ... -0.437189  0.900000 -0.288470\n",
              "1     Mixed      OVS  0.247000  ...  1.110112  0.900000  0.732484\n",
              "2     Mixed      SOV  0.247000  ...  1.039400  0.900000  0.636481\n",
              "3     Mixed      SVO  0.247000  ...  1.626818  0.705843  1.013971\n",
              "4     Mixed  Unknown  0.247000  ... -0.664528  0.900000 -0.438475\n",
              "5     Mixed      VOS  0.247000  ...  0.895268  0.900000  0.584787\n",
              "6     Mixed      VSO  0.247000  ... -0.744446  0.900000 -0.458120\n",
              "7       OSV      OVS  0.309500  ...  1.263366  0.900000  7.146677\n",
              "8       OSV      SOV  0.309500  ...  1.133705  0.900000  1.087122\n",
              "9       OSV      SVO  0.309500  ...  1.522325  0.763571  1.415160\n",
              "10      OSV  Unknown  0.309500  ... -0.185621  0.900000 -1.050032\n",
              "11      OSV      VOS  0.309500  ...  1.070240  0.900000  0.706175\n",
              "12      OSV      VSO  0.309500  ...  0.008088  0.900000  0.007701\n",
              "13      OVS      SOV  0.088300  ... -0.569817  0.900000 -0.546404\n",
              "14      OVS      SVO  0.088300  ... -0.148951  0.900000 -0.138466\n",
              "15      OVS  Unknown  0.088300  ... -1.448987  0.804082 -8.196709\n",
              "16      OVS      VOS  0.088300  ... -0.477061  0.900000 -0.314779\n",
              "17      OVS      VSO  0.088300  ... -1.686895  0.672651 -1.606065\n",
              "18      SOV      SVO  0.162290  ...  0.889588  0.900000  0.416103\n",
              "19      SOV  Unknown  0.162290  ... -1.383996  0.839988 -1.327129\n",
              "20      SOV      VOS  0.162290  ...  0.071044  0.900000  0.043504\n",
              "21      SOV      VSO  0.162290  ... -2.569304  0.210563 -1.127655\n",
              "22      SVO  Unknown  0.108014  ... -1.767879  0.627914 -1.643428\n",
              "23      SVO      VOS  0.108014  ... -0.567522  0.900000 -0.353728\n",
              "24      SVO      VSO  0.108014  ... -3.212421  0.058051 -1.530604\n",
              "25  Unknown      VOS  0.342000  ...  1.297578  0.887728  0.856180\n",
              "26  Unknown      VSO  0.342000  ...  0.257125  0.900000  0.244805\n",
              "27      VOS      VSO  0.156500  ... -1.840921  0.587561 -1.132874\n",
              "\n",
              "[28 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "VYaHCtVI0iBq",
        "outputId": "e39be9b2-1646-4474-e5bb-780db79f905c"
      },
      "source": [
        "pg.pairwise_tukey(data=simple_zero_shot_laser, dv='Average F1 (LASER)', between='Basic Word Order')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>mean(A)</th>\n",
              "      <th>mean(B)</th>\n",
              "      <th>diff</th>\n",
              "      <th>se</th>\n",
              "      <th>T</th>\n",
              "      <th>p-tukey</th>\n",
              "      <th>hedges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>OSV</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.100900</td>\n",
              "      <td>0.116725</td>\n",
              "      <td>0.864425</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.570372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>OVS</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.124800</td>\n",
              "      <td>0.116725</td>\n",
              "      <td>1.069180</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.705476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>SOV</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.034200</td>\n",
              "      <td>0.064312</td>\n",
              "      <td>0.531780</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.321120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>0.056517</td>\n",
              "      <td>0.065251</td>\n",
              "      <td>0.866139</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.526203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>0.272100</td>\n",
              "      <td>-0.145800</td>\n",
              "      <td>0.116725</td>\n",
              "      <td>-1.249090</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.824185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.043600</td>\n",
              "      <td>0.082537</td>\n",
              "      <td>0.528248</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.345050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mixed</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>0.031630</td>\n",
              "      <td>0.066543</td>\n",
              "      <td>0.475328</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.291069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OSV</td>\n",
              "      <td>OVS</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.142958</td>\n",
              "      <td>0.167182</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.945722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>OSV</td>\n",
              "      <td>SOV</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>-0.066700</td>\n",
              "      <td>0.104635</td>\n",
              "      <td>-0.637455</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.621015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>OSV</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>-0.044383</td>\n",
              "      <td>0.105215</td>\n",
              "      <td>-0.421837</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.408429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>OSV</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.272100</td>\n",
              "      <td>-0.246700</td>\n",
              "      <td>0.142958</td>\n",
              "      <td>-1.725677</td>\n",
              "      <td>0.650491</td>\n",
              "      <td>-9.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>OSV</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>-0.057300</td>\n",
              "      <td>0.116725</td>\n",
              "      <td>-0.490897</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.323908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>OSV</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>-0.069270</td>\n",
              "      <td>0.106021</td>\n",
              "      <td>-0.653363</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.626517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>OVS</td>\n",
              "      <td>SOV</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>-0.090600</td>\n",
              "      <td>0.104635</td>\n",
              "      <td>-0.865869</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.843538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>OVS</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>-0.068283</td>\n",
              "      <td>0.105215</td>\n",
              "      <td>-0.648992</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.628365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>OVS</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.272100</td>\n",
              "      <td>-0.270600</td>\n",
              "      <td>0.142958</td>\n",
              "      <td>-1.892859</td>\n",
              "      <td>0.556142</td>\n",
              "      <td>-10.707627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>OVS</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>-0.081200</td>\n",
              "      <td>0.116725</td>\n",
              "      <td>-0.695652</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.459011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>OVS</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>-0.093170</td>\n",
              "      <td>0.106021</td>\n",
              "      <td>-0.878790</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.842682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SOV</td>\n",
              "      <td>SVO</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>0.022317</td>\n",
              "      <td>0.039767</td>\n",
              "      <td>0.561181</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.213796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SOV</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.272100</td>\n",
              "      <td>-0.180000</td>\n",
              "      <td>0.104635</td>\n",
              "      <td>-1.720269</td>\n",
              "      <td>0.653542</td>\n",
              "      <td>-1.675904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>SOV</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.009400</td>\n",
              "      <td>0.064312</td>\n",
              "      <td>0.146162</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.088261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>SOV</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>-0.002570</td>\n",
              "      <td>0.041854</td>\n",
              "      <td>-0.061404</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.024547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>SVO</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>0.272100</td>\n",
              "      <td>-0.202317</td>\n",
              "      <td>0.105215</td>\n",
              "      <td>-1.922897</td>\n",
              "      <td>0.539189</td>\n",
              "      <td>-1.861781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>SVO</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>-0.012917</td>\n",
              "      <td>0.065251</td>\n",
              "      <td>-0.197953</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.120262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>SVO</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>-0.024887</td>\n",
              "      <td>0.043283</td>\n",
              "      <td>-0.574978</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.236842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Unknown</td>\n",
              "      <td>VOS</td>\n",
              "      <td>0.272100</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.189400</td>\n",
              "      <td>0.116725</td>\n",
              "      <td>1.622617</td>\n",
              "      <td>0.708650</td>\n",
              "      <td>1.070650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unknown</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.272100</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>0.177430</td>\n",
              "      <td>0.106021</td>\n",
              "      <td>1.673540</td>\n",
              "      <td>0.679914</td>\n",
              "      <td>1.604776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>VOS</td>\n",
              "      <td>VSO</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>-0.011970</td>\n",
              "      <td>0.066543</td>\n",
              "      <td>-0.179882</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-0.110152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          A        B   mean(A)  ...         T   p-tukey     hedges\n",
              "0     Mixed      OSV  0.126300  ...  0.864425  0.900000   0.570372\n",
              "1     Mixed      OVS  0.126300  ...  1.069180  0.900000   0.705476\n",
              "2     Mixed      SOV  0.126300  ...  0.531780  0.900000   0.321120\n",
              "3     Mixed      SVO  0.126300  ...  0.866139  0.900000   0.526203\n",
              "4     Mixed  Unknown  0.126300  ... -1.249090  0.900000  -0.824185\n",
              "5     Mixed      VOS  0.126300  ...  0.528248  0.900000   0.345050\n",
              "6     Mixed      VSO  0.126300  ...  0.475328  0.900000   0.291069\n",
              "7       OSV      OVS  0.025400  ...  0.167182  0.900000   0.945722\n",
              "8       OSV      SOV  0.025400  ... -0.637455  0.900000  -0.621015\n",
              "9       OSV      SVO  0.025400  ... -0.421837  0.900000  -0.408429\n",
              "10      OSV  Unknown  0.025400  ... -1.725677  0.650491  -9.761905\n",
              "11      OSV      VOS  0.025400  ... -0.490897  0.900000  -0.323908\n",
              "12      OSV      VSO  0.025400  ... -0.653363  0.900000  -0.626517\n",
              "13      OVS      SOV  0.001500  ... -0.865869  0.900000  -0.843538\n",
              "14      OVS      SVO  0.001500  ... -0.648992  0.900000  -0.628365\n",
              "15      OVS  Unknown  0.001500  ... -1.892859  0.556142 -10.707627\n",
              "16      OVS      VOS  0.001500  ... -0.695652  0.900000  -0.459011\n",
              "17      OVS      VSO  0.001500  ... -0.878790  0.900000  -0.842682\n",
              "18      SOV      SVO  0.092100  ...  0.561181  0.900000   0.213796\n",
              "19      SOV  Unknown  0.092100  ... -1.720269  0.653542  -1.675904\n",
              "20      SOV      VOS  0.092100  ...  0.146162  0.900000   0.088261\n",
              "21      SOV      VSO  0.092100  ... -0.061404  0.900000  -0.024547\n",
              "22      SVO  Unknown  0.069783  ... -1.922897  0.539189  -1.861781\n",
              "23      SVO      VOS  0.069783  ... -0.197953  0.900000  -0.120262\n",
              "24      SVO      VSO  0.069783  ... -0.574978  0.900000  -0.236842\n",
              "25  Unknown      VOS  0.272100  ...  1.622617  0.708650   1.070650\n",
              "26  Unknown      VSO  0.272100  ...  1.673540  0.679914   1.604776\n",
              "27      VOS      VSO  0.082700  ... -0.179882  0.900000  -0.110152\n",
              "\n",
              "[28 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBhr_hDs5i9I"
      },
      "source": [
        "### Experimenting with sklearn models for feature selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3H-65nELVSa"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import chain, combinations # Used for exhaustive feature search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXjfTwnljXR3"
      },
      "source": [
        "# The model we'll use to choose the best features for predicting F1-score for LaBSE\n",
        "labse_f1_model = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL2Gghv-8Kje"
      },
      "source": [
        "# All the possible pair-centric LaBSE IVs\n",
        "labse_pair_iv = ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)',\n",
        "                 'Combined in-genus sentences (LaBSE)', 'Same Family?', 'Same Genus?',\n",
        "                 'Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)',\n",
        "                 'Token-level Overlap (multiset Jaccard coefficient, Book of John)',\n",
        "                 'Same Word Order?', 'Same Polysynthesis Status?', \n",
        "                 'Geographic Distance (lang2vec)', 'Syntactic Distance (lang2vec)',\n",
        "                 'Phonological Distance (lang2vec)', 'Inventory Distance (lang2vec)']\n",
        "X_pair_labse = master_pair[labse_pair_iv]\n",
        "\n",
        "# The first DV we'll look at\n",
        "y_pair_f1_labse = master_pair['F1-score (LaBSE, average)']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3C2Hp3f_1vZ"
      },
      "source": [
        "# Exhaustive feature search on language pair features\n",
        "def getBestFeatures(model, X, y, score_method):\n",
        "  FOLDS = 10\n",
        "  n_features = X.shape[1]\n",
        "  all_subsets = chain.from_iterable(combinations(range(n_features), k) for k in range(n_features+1))\n",
        "\n",
        "  best_score = -np.inf\n",
        "  best_features = None\n",
        "  for subset in all_subsets:\n",
        "    if len(subset)!=0: # Search over all non-empty subsets of features  \n",
        "      score_by_fold = sklearn.model_selection.cross_validate(model, \n",
        "                                                         X.iloc[:, np.array(subset)], \n",
        "                                                         y, \n",
        "                                                         cv=FOLDS, \n",
        "                                                         scoring=score_method)['test_score']\n",
        "                                                         #scoring='neg_mean_squared_error')\n",
        "\n",
        "      # Convert R2 to adjusted R2 to take into account the number of predictors\n",
        "      def adjustedR2(r2, n, p):\n",
        "        num = (1-r2)*(n-1)\n",
        "        denom = n-p-1\n",
        "        adj_r2 = 1 - (num/denom)\n",
        "        return adj_r2\n",
        "      \n",
        "      if score_method=='r2':\n",
        "        # Compute the adjusted R2 instead\n",
        "        n_subset_features = len(subset)\n",
        "        # Fraction of data used for training during CV\n",
        "        train_frac = (FOLDS-1) / FOLDS # e.g. with 10 folds, we use 9/10 of the data for training\n",
        "        sample_size = round(train_frac*X.shape[0])\n",
        "        score_by_fold = list(map(lambda r2: adjustedR2(r2,sample_size,n_subset_features), score_by_fold)) #[adjustedR2(r2, n_subset_features, sample_size) for r2 in score_by_fold]\n",
        "\n",
        "      score = np.average(score_by_fold)\n",
        "\n",
        "      # If score is current optimum . . .\n",
        "      if score > best_score:\n",
        "        best_score, best_features = score, subset # . . . flag it as such\n",
        "        print('Score: {} Features: {}'.format(best_score, [X.columns[i] for i in best_features]))\n",
        "\n",
        "  best_features = [X.columns[i] for i in best_features] # Return just the best features\n",
        "  return best_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDvDe6uHFwu9",
        "outputId": "af458c35-6071-4a5c-a7a8-cb244bbcdade"
      },
      "source": [
        "labse_pair_f1_best_features = getBestFeatures(model=labse_f1_model, \n",
        "                                              X=X_pair_labse, \n",
        "                                              y=y_pair_f1_labse,\n",
        "                                              score_method='r2') # really adjusted R2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.04128646949432839 Features: ['Combined sentences (LaBSE)']\n",
            "Score: 0.17838707077008623 Features: ['Combined in-family sentences (LaBSE)']\n",
            "Score: 0.22443671542909233 Features: ['Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.2941476121717451 Features: ['Combined sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.3153931783656644 Features: ['Combined in-family sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.3386625149111925 Features: ['Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?']\n",
            "Score: 0.3492214395987304 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.3872478837547058 Features: ['Combined sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?']\n",
            "Score: 0.4009222646126024 Features: ['Combined in-family sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?']\n",
            "Score: 0.4257946237905684 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?']\n",
            "Score: 0.4280964281852465 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tibykwXjI2Sn"
      },
      "source": [
        "# Repeating the same process for LASER\n",
        "\n",
        "# All the possible pair-centric LASER IVs\n",
        "laser_pair_iv = ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)',\n",
        "                 'Combined in-genus sentences (LASER)', 'Same Family?', 'Same Genus?',\n",
        "                 'Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)',\n",
        "                 'Token-level Overlap (multiset Jaccard coefficient, Book of John)',\n",
        "                 'Same Word Order?', 'Same Polysynthesis Status?', \n",
        "                 'Geographic Distance (lang2vec)', 'Syntactic Distance (lang2vec)',\n",
        "                 'Phonological Distance (lang2vec)', 'Inventory Distance (lang2vec)']\n",
        "X_pair_laser = master_pair[laser_pair_iv]\n",
        "\n",
        "# The first DV we'll look at (for LASER)\n",
        "y_pair_f1_laser = master_pair['F1-score (LASER, average)']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Erm0cQLkXL"
      },
      "source": [
        "laser_f1_model = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRyvDngxLdBm",
        "outputId": "3c73a0f3-81ae-4e22-c21c-d3383567bf18"
      },
      "source": [
        "laser_pair_f1_best_features = getBestFeatures(model=laser_f1_model, \n",
        "                                              X=X_pair_laser, \n",
        "                                              y=y_pair_f1_laser, \n",
        "                                              score_method='r2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: -0.01978130854908604 Features: ['Combined sentences (LASER)']\n",
            "Score: 0.25089903587019724 Features: ['Combined in-family sentences (LASER)']\n",
            "Score: 0.2781519844206934 Features: ['Combined in-family sentences (LASER)', 'Same Family?']\n",
            "Score: 0.31903495057038245 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.3316275968804237 Features: ['Combined in-family sentences (LASER)', 'Same Family?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.3482534147350469 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?']\n",
            "Score: 0.35438798384031955 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.36074765639270434 Features: ['Combined in-family sentences (LASER)', 'Same Family?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?']\n",
            "Score: 0.36195359973421626 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Geographic Distance (lang2vec)']\n",
            "Score: 0.3660700225060908 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.3689909119141931 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.3694833894592186 Features: ['Combined in-family sentences (LASER)', 'Same Family?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?']\n",
            "Score: 0.3703835734557118 Features: ['Combined in-family sentences (LASER)', 'Same Family?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.37823186943463705 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.3797975436317183 Features: ['Combined in-family sentences (LASER)', 'Same Family?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.3800551193435479 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.38065200958413714 Features: ['Combined in-family sentences (LASER)', 'Same Family?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.38200560070891776 Features: ['Combined in-family sentences (LASER)', 'Same Family?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)', 'Syntactic Distance (lang2vec)', 'Phonological Distance (lang2vec)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B7Ffa2TLq_h",
        "outputId": "5ea284aa-b6f4-4a98-b0b0-4ac81fde64ff"
      },
      "source": [
        "# Overlapping best predictors\n",
        "set(laser_pair_f1_best_features)&set(labse_pair_f1_best_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Geographic Distance (lang2vec)',\n",
              " 'Same Polysynthesis Status?',\n",
              " 'Token-level Overlap (multiset Jaccard coefficient, Book of John)'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfxfGtbqMENI"
      },
      "source": [
        "# Checking out the best predictors for the other DVs\n",
        "\n",
        "# LaBSE\n",
        "y_pair_gh_labse = master_pair['Gromov-Hausdorff dist. (LaBSE, average)']\n",
        "y_pair_svg_labse = master_pair['Singular value gap (LaBSE, average)']\n",
        "y_pair_econdhm_labse = master_pair['ECOND-HM (LaBSE, average)']\n",
        "y_pair_avgmarg_labse = master_pair['Average margin score (LaBSE, average)']\n",
        "labse_gh_model, labse_svg_model, labse_econdhm_model, labse_avgmarg_model = LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression()\n",
        "\n",
        "# LASER\n",
        "y_pair_gh_laser = master_pair['Gromov-Hausdorff dist. (LASER, average)']\n",
        "y_pair_svg_laser = master_pair['Singular value gap (LASER, average)']\n",
        "y_pair_econdhm_laser = master_pair['ECOND-HM (LASER, average)']\n",
        "y_pair_avgmarg_laser = master_pair['Average margin score (LASER, average)']\n",
        "laser_gh_model, laser_svg_model, laser_econdhm_model, laser_avgmarg_model = LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfJB9v_628B",
        "outputId": "827f6038-30dc-471b-a3fd-1f8d861b36c1"
      },
      "source": [
        "# LaBSE best feature selection\n",
        "print('Getting best features for LaBSE, GH')\n",
        "labse_pair_gh_best_features = getBestFeatures(labse_gh_model, X_pair_labse, y_pair_gh_labse, 'r2')\n",
        "print('Getting best features for LaBSE, SVG')\n",
        "labse_pair_svg_best_features = getBestFeatures(labse_svg_model, X_pair_labse, y_pair_svg_labse, 'r2')\n",
        "print('Getting best features for LaBSE, ECOND-HM')\n",
        "labse_pair_econdhm_best_features = getBestFeatures(labse_econdhm_model, X_pair_labse, y_pair_econdhm_labse, 'r2')\n",
        "print('Getting best features for LaBSE, avg. margin score')\n",
        "labse_pair_avgmarg_best_features = getBestFeatures(labse_avgmarg_model, X_pair_labse, y_pair_avgmarg_labse, 'r2')\n",
        "\n",
        "# LASER best feature selection\n",
        "print('Getting best features for LASER, GH')\n",
        "laser_pair_gh_best_features = getBestFeatures(laser_gh_model, X_pair_laser, y_pair_gh_laser, 'r2')\n",
        "print('Getting best features for LASER, SVG')\n",
        "laser_pair_svg_best_features = getBestFeatures(laser_svg_model, X_pair_laser, y_pair_svg_laser, 'r2')\n",
        "print('Getting best features for LASER, ECOND-HM')\n",
        "laser_pair_econdhm_best_features = getBestFeatures(laser_econdhm_model, X_pair_laser, y_pair_econdhm_laser, 'r2')\n",
        "print('Getting best features for LASER, avg. margin score')\n",
        "laser_pair_avgmarg_best_features = getBestFeatures(laser_avgmarg_model, X_pair_laser, y_pair_avgmarg_laser, 'r2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting best features for LaBSE, GH\n",
            "Score: -0.0413396886380951 Features: ['Combined sentences (LaBSE)']\n",
            "Score: -0.021350223866934324 Features: ['Combined in-family sentences (LaBSE)']\n",
            "Score: -0.01679224278785668 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)']\n",
            "Score: -0.002414935334796575 Features: ['Combined in-family sentences (LaBSE)', 'Same Word Order?']\n",
            "Score: 0.0003457227233038096 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Same Word Order?']\n",
            "Score: 0.0042619988612207175 Features: ['Combined in-family sentences (LaBSE)', 'Same Word Order?', 'Same Polysynthesis Status?']\n",
            "Score: 0.006178065339854944 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Same Word Order?', 'Same Polysynthesis Status?']\n",
            "Score: 0.007388992714442766 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)']\n",
            "Getting best features for LaBSE, SVG\n",
            "Score: -13.442845600864931 Features: ['Combined sentences (LaBSE)']\n",
            "Score: -12.91560970563965 Features: ['Same Family?']\n",
            "Score: -12.70894889458604 Features: ['Same Genus?']\n",
            "Getting best features for LaBSE, ECOND-HM\n",
            "Score: -0.07663792223141372 Features: ['Combined sentences (LaBSE)']\n",
            "Score: 0.17450005561272933 Features: ['Combined in-family sentences (LaBSE)']\n",
            "Score: 0.18470724634286412 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)']\n",
            "Score: 0.18710971735580179 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Combined in-genus sentences (LaBSE)']\n",
            "Score: 0.19515508854609553 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Same Polysynthesis Status?']\n",
            "Score: 0.1972223430662685 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Combined in-genus sentences (LaBSE)', 'Same Polysynthesis Status?']\n",
            "Score: 0.19857398579111657 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Combined in-genus sentences (LaBSE)', 'Same Family?', 'Same Polysynthesis Status?']\n",
            "Getting best features for LaBSE, avg. margin score\n",
            "Score: 0.003132645432362735 Features: ['Combined sentences (LaBSE)']\n",
            "Score: 0.08877712075136177 Features: ['Combined in-family sentences (LaBSE)']\n",
            "Score: 0.11039046088757831 Features: ['Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.13403592045753307 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)']\n",
            "Score: 0.17985617121967118 Features: ['Combined sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)']\n",
            "Score: 0.21704669662166767 Features: ['Combined in-family sentences (LaBSE)', 'Same Polysynthesis Status?']\n",
            "Score: 0.22581187960281346 Features: ['Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?']\n",
            "Score: 0.24842980585512003 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Same Polysynthesis Status?']\n",
            "Score: 0.27335157866345083 Features: ['Combined sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?']\n",
            "Score: 0.297625168503587 Features: ['Combined sentences (LaBSE)', 'Combined in-family sentences (LaBSE)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Polysynthesis Status?']\n",
            "Getting best features for LASER, GH\n",
            "Score: -0.04232319615283292 Features: ['Combined sentences (LASER)']\n",
            "Score: -0.011643389665897275 Features: ['Combined in-family sentences (LASER)']\n",
            "Score: -0.011590823223872415 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)']\n",
            "Score: -0.011067803063791825 Features: ['Combined in-family sentences (LASER)', 'Same Family?']\n",
            "Score: 0.009656949432331452 Features: ['Combined in-family sentences (LASER)', 'Same Word Order?']\n",
            "Score: 0.01582487308917795 Features: ['Combined in-family sentences (LASER)', 'Same Word Order?', 'Same Polysynthesis Status?']\n",
            "Score: 0.01741500169028971 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?']\n",
            "Score: 0.01914508611124365 Features: ['Combined in-family sentences (LASER)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)']\n",
            "Score: 0.02014953773989433 Features: ['Combined in-family sentences (LASER)', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)']\n",
            "Score: 0.020236921735400204 Features: ['Combined in-family sentences (LASER)', 'Same Genus?', 'Token-level Overlap (multiset Jaccard coefficient, Book of John)', 'Same Word Order?', 'Same Polysynthesis Status?', 'Geographic Distance (lang2vec)']\n",
            "Getting best features for LASER, SVG\n",
            "Score: -2.1239321109011433 Features: ['Combined sentences (LASER)']\n",
            "Score: -2.087700196995328 Features: ['Combined in-family sentences (LASER)']\n",
            "Score: -2.03830090855165 Features: ['Combined in-genus sentences (LASER)']\n",
            "Score: -2.037664077793555 Features: ['Same Family?']\n",
            "Score: -2.0058829314780606 Features: ['Same Word Order?']\n",
            "Score: -1.9890764864614519 Features: ['Combined in-genus sentences (LASER)', 'Same Word Order?']\n",
            "Getting best features for LASER, ECOND-HM\n",
            "Score: -0.08398775179803149 Features: ['Combined sentences (LASER)']\n",
            "Score: 0.033989541419546 Features: ['Combined in-family sentences (LASER)']\n",
            "Score: 0.05607357917655924 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)']\n",
            "Score: 0.07199849287006928 Features: ['Combined in-family sentences (LASER)', 'Same Polysynthesis Status?']\n",
            "Score: 0.09467553484494366 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Polysynthesis Status?']\n",
            "Score: 0.10073009738796554 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Family?', 'Same Polysynthesis Status?']\n",
            "Score: 0.10155085237237542 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.11599358877094387 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Family?', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.1165912748426974 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Family?', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)', 'Phonological Distance (lang2vec)']\n",
            "Getting best features for LASER, avg. margin score\n",
            "Score: -0.08558564615220951 Features: ['Combined sentences (LASER)']\n",
            "Score: 0.028976489862599188 Features: ['Combined in-family sentences (LASER)']\n",
            "Score: 0.0623230762576779 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)']\n",
            "Score: 0.06384934429762971 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Family?']\n",
            "Score: 0.07024430593135979 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Word Order?']\n",
            "Score: 0.07052342218821048 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Polysynthesis Status?']\n",
            "Score: 0.08030722587494216 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.08734223706788617 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)']\n",
            "Score: 0.08791708013904954 Features: ['Combined sentences (LASER)', 'Combined in-family sentences (LASER)', 'Same Polysynthesis Status?', 'Syntactic Distance (lang2vec)', 'Phonological Distance (lang2vec)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ooDv1HOXvXY"
      },
      "source": [
        "### Applying PCA as an additional feature selection tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8h0GYI7HTww"
      },
      "source": [
        "pca = sklearn.decomposition.PCA(n_components=5)\n",
        "labse_pair_pca = pca.fit_transform(X_pair_labse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QnfkjU3YJ33",
        "outputId": "b2d408ec-14cb-4571-bca4-0e4d706f884c"
      },
      "source": [
        "labse_pair_pca.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5050, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxXCVBenWr6L"
      },
      "source": [
        "### PCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2gxSy3ZYpG4"
      },
      "source": [
        "# Implement principal component regression (PCR)\n",
        "def PCR(model, X, y, n_components, score_method):\n",
        "    FOLDS = 10\n",
        "    pca = sklearn.decomposition.PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    score_by_fold = sklearn.model_selection.cross_validate(model, \n",
        "                                                         X_pca, \n",
        "                                                         y, \n",
        "                                                         cv=FOLDS, \n",
        "                                                         scoring=score_method)['test_score']\n",
        "    # Convert R2 to adjusted R2 to take into account the number of predictors\n",
        "    def adjustedR2(r2, n, p):\n",
        "        num = (1-r2)*(n-1)\n",
        "        denom = n-p-1\n",
        "        adj_r2 = 1 - (num/denom)\n",
        "        return adj_r2\n",
        "      \n",
        "    if score_method=='r2':\n",
        "        # Compute the adjusted R2 instead\n",
        "        n_subset_features = X.shape[1]\n",
        "        # Fraction of data used for training during CV\n",
        "        train_frac = (FOLDS-1) / FOLDS # e.g. with 10 folds, we use 9/10 of the data for training\n",
        "        sample_size = round(train_frac*X.shape[0])\n",
        "        score_by_fold = list(map(lambda r2: adjustedR2(r2,sample_size,n_subset_features), score_by_fold)) #[adjustedR2(r2, n_subset_features, sample_size) for r2 in score_by_fold]\n",
        "\n",
        "    score = np.average(score_by_fold)                                     \n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J0Ka9PdbPlD"
      },
      "source": [
        "def optimizeComponentsPCR(X, y, score_method):\n",
        "  score_list = []\n",
        "  for n in range(1, X.shape[1]+1):\n",
        "    lr_model = LinearRegression()\n",
        "    score_n = PCR(lr_model, X, y, n, score_method)\n",
        "    score_list.append(score_n)\n",
        "    print('Number of components: {} | Score: {}'.format(n, score_n))\n",
        "  return max(enumerate(score_list), key=lambda x: x[1])[0]+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qlu5_81gmdp",
        "outputId": "03150046-f2db-4a35-bf57-1d99c994faba"
      },
      "source": [
        "# Computing the optimal number of components for predicting each of our DVs (LaBSE)\n",
        "\n",
        "labse_best_components = []\n",
        "\n",
        "print('Getting best number of components for predicting F1-score (LaBSE)')\n",
        "res1 = optimizeComponentsPCR(X_pair_labse, y_pair_f1_labse, 'r2')\n",
        "print('Optimal components: {}'.format(res1))\n",
        "labse_best_components.append(res1)\n",
        "\n",
        "print('Getting best number of components for predicting G-H dist. (LaBSE)')\n",
        "res2 = optimizeComponentsPCR(X_pair_labse, y_pair_gh_labse, 'r2')\n",
        "print('Optimal components: {}'.format(res2))\n",
        "labse_best_components.append(res2)\n",
        "\n",
        "print('Getting best number of components for predicting SVG (LaBSE)')\n",
        "res3 = optimizeComponentsPCR(X_pair_labse, y_pair_svg_labse, 'r2')\n",
        "print('Optimal components: {}'.format(res3))\n",
        "labse_best_components.append(res3)\n",
        "\n",
        "print('Getting best number of components for predicting ECOND-HM (LaBSE)')\n",
        "res4 = optimizeComponentsPCR(X_pair_labse, y_pair_econdhm_labse, 'r2')\n",
        "print('Optimal components: {}'.format(res4))\n",
        "labse_best_components.append(res4)\n",
        "\n",
        "print('Getting best number of components for predicting avg. margin score (LaBSE)')\n",
        "res5 = optimizeComponentsPCR(X_pair_labse, y_pair_avgmarg_labse, 'r2')\n",
        "print('Optimal components: {}'.format(res5))\n",
        "labse_best_components.append(res5)\n",
        "\n",
        "print('\\nAverage best number of components (LaBSE): {}'.format(np.average(labse_best_components)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting best number of components for predicting F1-score (LaBSE)\n",
            "Number of components: 1 | Score: 0.17972379521571577\n",
            "Number of components: 2 | Score: 0.1901240819549382\n",
            "Number of components: 3 | Score: 0.21476442655085473\n",
            "Number of components: 4 | Score: 0.29956825492307526\n",
            "Number of components: 5 | Score: 0.34289235673145446\n",
            "Number of components: 6 | Score: 0.3421048165496681\n",
            "Number of components: 7 | Score: 0.3372982915953129\n",
            "Number of components: 8 | Score: 0.3360520687440106\n",
            "Number of components: 9 | Score: 0.3335706883430518\n",
            "Number of components: 10 | Score: 0.3312733377591113\n",
            "Number of components: 11 | Score: 0.4039158484777078\n",
            "Number of components: 12 | Score: 0.4075171131971723\n",
            "Number of components: 13 | Score: 0.4070012098494723\n",
            "Optimal components: 12\n",
            "Getting best number of components for predicting G-H dist. (LaBSE)\n",
            "Number of components: 1 | Score: -0.023450041867626937\n",
            "Number of components: 2 | Score: -0.022016428319914638\n",
            "Number of components: 3 | Score: -0.019884421939913976\n",
            "Number of components: 4 | Score: 0.00909835522611423\n",
            "Number of components: 5 | Score: 0.004125602923978655\n",
            "Number of components: 6 | Score: 0.003271217259553949\n",
            "Number of components: 7 | Score: -0.003200684233527129\n",
            "Number of components: 8 | Score: -0.0035266503736736342\n",
            "Number of components: 9 | Score: -0.016886078448594754\n",
            "Number of components: 10 | Score: -0.020666874055134076\n",
            "Number of components: 11 | Score: -0.01911219759191459\n",
            "Number of components: 12 | Score: -0.021771350806071576\n",
            "Number of components: 13 | Score: -0.021459883412738846\n",
            "Optimal components: 4\n",
            "Getting best number of components for predicting SVG (LaBSE)\n",
            "Number of components: 1 | Score: -15.327637555806144\n",
            "Number of components: 2 | Score: -15.170055032880992\n",
            "Number of components: 3 | Score: -15.348415463605608\n",
            "Number of components: 4 | Score: -15.723437710804806\n",
            "Number of components: 5 | Score: -20.138578085396354\n",
            "Number of components: 6 | Score: -20.22582664045378\n",
            "Number of components: 7 | Score: -26.17349375339247\n",
            "Number of components: 8 | Score: -26.338045762239894\n",
            "Number of components: 9 | Score: -27.895656205308597\n",
            "Number of components: 10 | Score: -30.258586287075996\n",
            "Number of components: 11 | Score: -30.659528153335394\n",
            "Number of components: 12 | Score: -33.59505881116864\n",
            "Number of components: 13 | Score: -33.5589871805668\n",
            "Optimal components: 2\n",
            "Getting best number of components for predicting ECOND-HM (LaBSE)\n",
            "Number of components: 1 | Score: 0.17240243596218333\n",
            "Number of components: 2 | Score: 0.17070721517851442\n",
            "Number of components: 3 | Score: 0.18531565361127683\n",
            "Number of components: 4 | Score: 0.18461839643528005\n",
            "Number of components: 5 | Score: 0.19525640859385313\n",
            "Number of components: 6 | Score: 0.1983754682800799\n",
            "Number of components: 7 | Score: 0.17397518755381663\n",
            "Number of components: 8 | Score: 0.17525965113784145\n",
            "Number of components: 9 | Score: 0.16983126022206396\n",
            "Number of components: 10 | Score: 0.1656266328722466\n",
            "Number of components: 11 | Score: 0.11960482469443368\n",
            "Number of components: 12 | Score: 0.0718231184334466\n",
            "Number of components: 13 | Score: 0.06989622254615739\n",
            "Optimal components: 6\n",
            "Getting best number of components for predicting avg. margin score (LaBSE)\n",
            "Number of components: 1 | Score: 0.09010179162968665\n",
            "Number of components: 2 | Score: 0.10532237744780584\n",
            "Number of components: 3 | Score: 0.13163965015930104\n",
            "Number of components: 4 | Score: 0.21540326700058202\n",
            "Number of components: 5 | Score: 0.2556903557196278\n",
            "Number of components: 6 | Score: 0.25530312961692075\n",
            "Number of components: 7 | Score: 0.2500554679730965\n",
            "Number of components: 8 | Score: 0.24878856597548843\n",
            "Number of components: 9 | Score: 0.24146731977725172\n",
            "Number of components: 10 | Score: 0.23949006569759934\n",
            "Number of components: 11 | Score: 0.26486129986939516\n",
            "Number of components: 12 | Score: 0.26686805094549276\n",
            "Number of components: 13 | Score: 0.26614060820906227\n",
            "Optimal components: 12\n",
            "\n",
            "Average best number of components (LaBSE): 7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuhfxq8WiMJa",
        "outputId": "1c62ceef-8829-489d-b592-935d84ae0807"
      },
      "source": [
        "# Computing the optimal number of components for predicting each of our DVs (LASER)\n",
        "\n",
        "laser_best_components = []\n",
        "\n",
        "print('Getting best number of components for predicting F1-score (LASER)')\n",
        "res1 = optimizeComponentsPCR(X_pair_laser, y_pair_f1_laser, 'r2')\n",
        "print('Optimal components: {}'.format(res1))\n",
        "laser_best_components.append(res1)\n",
        "\n",
        "print('Getting best number of components for predicting G-H dist. (LASER)')\n",
        "res2 = optimizeComponentsPCR(X_pair_laser, y_pair_gh_laser, 'r2')\n",
        "print('Optimal components: {}'.format(res2))\n",
        "laser_best_components.append(res2)\n",
        "\n",
        "print('Getting best number of components for predicting SVG (LASER)')\n",
        "res3 = optimizeComponentsPCR(X_pair_laser, y_pair_svg_laser, 'r2')\n",
        "print('Optimal components: {}'.format(res3))\n",
        "laser_best_components.append(res3)\n",
        "\n",
        "print('Getting best number of components for predicting ECOND-HM (LASER)')\n",
        "res4 = optimizeComponentsPCR(X_pair_laser, y_pair_econdhm_laser, 'r2')\n",
        "print('Optimal components: {}'.format(res4))\n",
        "laser_best_components.append(res4)\n",
        "\n",
        "print('Getting best number of components for predicting avg. margin score (LASER)')\n",
        "res5 = optimizeComponentsPCR(X_pair_laser, y_pair_avgmarg_laser, 'r2')\n",
        "print('Optimal components: {}'.format(res5))\n",
        "laser_best_components.append(res5)\n",
        "\n",
        "print('\\nAverage best number of components (LASER): {}'.format(np.average(laser_best_components)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting best number of components for predicting F1-score (LASER)\n",
            "Number of components: 1 | Score: 0.25132995699234767\n",
            "Number of components: 2 | Score: 0.24533497663419532\n",
            "Number of components: 3 | Score: 0.24429672952637901\n",
            "Number of components: 4 | Score: 0.32625652037710645\n",
            "Number of components: 5 | Score: 0.324452619728815\n",
            "Number of components: 6 | Score: 0.33632049976740347\n",
            "Number of components: 7 | Score: 0.3330385036809088\n",
            "Number of components: 8 | Score: 0.3315329782183334\n",
            "Number of components: 9 | Score: 0.34004006789883046\n",
            "Number of components: 10 | Score: 0.3454269658345027\n",
            "Number of components: 11 | Score: 0.37131678954138614\n",
            "Number of components: 12 | Score: 0.36917892682023223\n",
            "Number of components: 13 | Score: 0.36910899491731164\n",
            "Optimal components: 11\n",
            "Getting best number of components for predicting G-H dist. (LASER)\n",
            "Number of components: 1 | Score: -0.015035956926025273\n",
            "Number of components: 2 | Score: -0.015123503675341422\n",
            "Number of components: 3 | Score: -0.013855788261972046\n",
            "Number of components: 4 | Score: 0.018119577453560652\n",
            "Number of components: 5 | Score: 0.012091670481161932\n",
            "Number of components: 6 | Score: 0.011570117389545654\n",
            "Number of components: 7 | Score: 0.006528029298617133\n",
            "Number of components: 8 | Score: 0.005809074326431041\n",
            "Number of components: 9 | Score: -0.0020434895764344873\n",
            "Number of components: 10 | Score: -0.007913653166674573\n",
            "Number of components: 11 | Score: -0.004456867117794383\n",
            "Number of components: 12 | Score: -0.007335936437130874\n",
            "Number of components: 13 | Score: -0.006800213465730199\n",
            "Optimal components: 4\n",
            "Getting best number of components for predicting SVG (LASER)\n",
            "Number of components: 1 | Score: -2.092335835039092\n",
            "Number of components: 2 | Score: -2.0953046899998853\n",
            "Number of components: 3 | Score: -2.1048317282868187\n",
            "Number of components: 4 | Score: -2.2438478980664636\n",
            "Number of components: 5 | Score: -2.462178615394362\n",
            "Number of components: 6 | Score: -2.529091627679765\n",
            "Number of components: 7 | Score: -3.8417726735413944\n",
            "Number of components: 8 | Score: -3.88208279102322\n",
            "Number of components: 9 | Score: -3.62729747769029\n",
            "Number of components: 10 | Score: -3.7558858385761056\n",
            "Number of components: 11 | Score: -3.7403916673114375\n",
            "Number of components: 12 | Score: -4.192159341439939\n",
            "Number of components: 13 | Score: -4.171736703881545\n",
            "Optimal components: 1\n",
            "Getting best number of components for predicting ECOND-HM (LASER)\n",
            "Number of components: 1 | Score: 0.02406136741858822\n",
            "Number of components: 2 | Score: 0.038590178900507324\n",
            "Number of components: 3 | Score: 0.053384939847624935\n",
            "Number of components: 4 | Score: 0.07516391377271717\n",
            "Number of components: 5 | Score: 0.08662986056238306\n",
            "Number of components: 6 | Score: 0.09745978213582872\n",
            "Number of components: 7 | Score: 0.0916740163540157\n",
            "Number of components: 8 | Score: 0.09169259044772156\n",
            "Number of components: 9 | Score: 0.10009273047292475\n",
            "Number of components: 10 | Score: 0.10446411769286446\n",
            "Number of components: 11 | Score: 0.08806274092131895\n",
            "Number of components: 12 | Score: 0.08274294196038093\n",
            "Number of components: 13 | Score: 0.0881484428879068\n",
            "Optimal components: 10\n",
            "Getting best number of components for predicting avg. margin score (LASER)\n",
            "Number of components: 1 | Score: 0.020245403773229077\n",
            "Number of components: 2 | Score: 0.03262116728466258\n",
            "Number of components: 3 | Score: 0.05925128565550993\n",
            "Number of components: 4 | Score: 0.07978972709241317\n",
            "Number of components: 5 | Score: 0.07751119669949094\n",
            "Number of components: 6 | Score: 0.07687859192950443\n",
            "Number of components: 7 | Score: 0.06303077147862242\n",
            "Number of components: 8 | Score: 0.0609031941020155\n",
            "Number of components: 9 | Score: 0.07182133673477151\n",
            "Number of components: 10 | Score: 0.06734702514129629\n",
            "Number of components: 11 | Score: 0.032973086274687646\n",
            "Number of components: 12 | Score: -0.012399648033380761\n",
            "Number of components: 13 | Score: -0.02237236910831223\n",
            "Optimal components: 4\n",
            "\n",
            "Average best number of components (LASER): 6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckg-PavZ8dmA"
      },
      "source": [
        "# Perform ablation analysis to see how removing each predictor individually affects the regression fit\n",
        "def ablateLinReg(X, y, score_method):\n",
        "  FOLDS = 10\n",
        "  n_features = X.shape[1]\n",
        "  ablation_feature_diffs = {}\n",
        "\n",
        "  model = LinearRegression()\n",
        "\n",
        "  # Convert R2 to adjusted R2 to take into account the number of predictors\n",
        "  def adjustedR2(r2, n, p):\n",
        "    num = (1-r2)*(n-1)\n",
        "    denom = n-p-1\n",
        "    adj_r2 = 1 - (num/denom)\n",
        "    return adj_r2\n",
        "\n",
        "  # Getting baseline score using all the features\n",
        "  score_by_fold = sklearn.model_selection.cross_validate(model,\n",
        "                                                         X,\n",
        "                                                         y,\n",
        "                                                         cv=FOLDS,\n",
        "                                                         scoring=score_method)['test_score']\n",
        "  if score_method=='r2':\n",
        "        # Compute the adjusted R2 instead\n",
        "        N = n_features-1\n",
        "        # Fraction of data used for training during CV\n",
        "        train_frac = (FOLDS-1) / FOLDS # e.g. with 10 folds, we use 9/10 of the data for training\n",
        "        sample_size = round(train_frac*X.shape[0])\n",
        "        score_by_fold = list(map(lambda r2: adjustedR2(r2, sample_size, N), score_by_fold))  \n",
        "  baseline_score = np.average(score_by_fold)                                                    \n",
        "                                                \n",
        "\n",
        "  # We'll drop each of the features one-by-one and see how the fit (adjusted R2) of the model changes\n",
        "  for i in range(n_features):\n",
        "    dropped_feature = X.columns[i]\n",
        "    X_ablated = X.drop(columns=dropped_feature) # Ablated feature space\n",
        "    score_by_fold = sklearn.model_selection.cross_validate(model, \n",
        "                                                         X_ablated, \n",
        "                                                         y, \n",
        "                                                         cv=FOLDS, \n",
        "                                                         scoring=score_method)['test_score']\n",
        "                                          \n",
        "    if score_method=='r2':\n",
        "        # Compute the adjusted R2 instead\n",
        "        N = n_features-1\n",
        "        # Fraction of data used for training during CV\n",
        "        train_frac = (FOLDS-1) / FOLDS # e.g. with 10 folds, we use 9/10 of the data for training\n",
        "        sample_size = round(train_frac*X.shape[0])\n",
        "        score_by_fold = list(map(lambda r2: adjustedR2(r2, sample_size, N), score_by_fold)) \n",
        "      \n",
        "    score_diff = baseline_score - np.average(score_by_fold)\n",
        "    # The higher the score_diff, the more important that feature is\n",
        "    ablation_feature_diffs[dropped_feature] = score_diff\n",
        "\n",
        "  # Return dictionary sorted in descending order\n",
        "  ablation_feature_diffs = {k: v for k, v in sorted(ablation_feature_diffs.items(), key=lambda item: item[1], reverse=True)}\n",
        "  for k,v in zip(ablation_feature_diffs.keys(), ablation_feature_diffs.values()):\n",
        "    print('Dropped feature: {} | Score difference: {}'.format(k, v))\n",
        "  print('\\n')\n",
        "  return ablation_feature_diffs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B27LIgvD2-oM",
        "outputId": "b5ecff6b-0500-46d3-9d02-3cd3487b03cf"
      },
      "source": [
        "print('LaBSE F1-score ablation experiment')\n",
        "labse_f1_ablation = ablateLinReg(X_pair_labse, y_pair_f1_labse, 'r2')\n",
        "print('LaBSE GH dist. ablation experiment')\n",
        "labse_gh_ablation = ablateLinReg(X_pair_labse, y_pair_gh_labse, 'r2')\n",
        "print('LaBSE SVG ablation experiment')\n",
        "labse_svg_ablation = ablateLinReg(X_pair_labse, y_pair_svg_labse, 'r2')\n",
        "print('LaBSE ECOND-HM ablation experiment')\n",
        "labse_econdhm_ablation = ablateLinReg(X_pair_labse, y_pair_econdhm_labse, 'r2')\n",
        "print('LaBSE avg. margin score ablation experiment')\n",
        "labse_avgmarg_ablation = ablateLinReg(X_pair_labse, y_pair_avgmarg_labse, 'r2')\n",
        "\n",
        "print('LASER F1-score ablation experiment')\n",
        "laser_f1_ablation = ablateLinReg(X_pair_laser, y_pair_f1_laser, 'r2')\n",
        "print('LASER GH dist. ablation experiment')\n",
        "laser_gh_ablation = ablateLinReg(X_pair_laser, y_pair_gh_laser, 'r2')\n",
        "print('LASER SVG ablation experiment')\n",
        "laser_svg_ablation = ablateLinReg(X_pair_laser, y_pair_svg_laser, 'r2')\n",
        "print('LASER ECOND-HM ablation experiment')\n",
        "laser_econdhm_ablation = ablateLinReg(X_pair_laser, y_pair_econdhm_laser, 'r2')\n",
        "print('LASER avg. margin score ablation experiment')\n",
        "laser_avgmarg_ablation = ablateLinReg(X_pair_laser, y_pair_avgmarg_laser, 'r2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LaBSE F1-score ablation experiment\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: 0.08709077917140412\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.07801459067082295\n",
            "Dropped feature: Combined in-family sentences (LaBSE) | Score difference: 0.021541212157679013\n",
            "Dropped feature: Combined sentences (LaBSE) | Score difference: 0.017490943900182687\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: 0.0011430479674968685\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: 0.0001029806808426903\n",
            "Dropped feature: Same Genus? | Score difference: -0.0001531678426618388\n",
            "Dropped feature: Same Family? | Score difference: -0.0007611213982388065\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.0008741335340861633\n",
            "Dropped feature: Combined in-genus sentences (LaBSE) | Score difference: -0.0018140830062930435\n",
            "Dropped feature: Same Word Order? | Score difference: -0.0018827690611165626\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: -0.002441537556928719\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.013319129609875913\n",
            "\n",
            "\n",
            "LaBSE GH dist. ablation experiment\n",
            "Dropped feature: Same Word Order? | Score difference: 0.006897161648695593\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.00645739364107778\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: 0.0023524478594463827\n",
            "Dropped feature: Combined in-family sentences (LaBSE) | Score difference: 0.0008682008555018113\n",
            "Dropped feature: Same Genus? | Score difference: -2.759898914258402e-05\n",
            "Dropped feature: Combined sentences (LaBSE) | Score difference: -0.00030655642704104785\n",
            "Dropped feature: Same Family? | Score difference: -0.0008277636397534191\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: -0.0009677888537195992\n",
            "Dropped feature: Combined in-genus sentences (LaBSE) | Score difference: -0.0013085775103701472\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.0038018125687619628\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: -0.005744979994610077\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: -0.007565268961590954\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.008039777900211409\n",
            "\n",
            "\n",
            "LaBSE SVG ablation experiment\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: 0.5141641599718483\n",
            "Dropped feature: Combined sentences (LaBSE) | Score difference: 0.22714934044942225\n",
            "Dropped feature: Same Genus? | Score difference: -0.016431399398932456\n",
            "Dropped feature: Combined in-genus sentences (LaBSE) | Score difference: -0.03781069649957658\n",
            "Dropped feature: Same Family? | Score difference: -0.11725021464062024\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: -0.39791610304009595\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: -0.8385217008515014\n",
            "Dropped feature: Same Word Order? | Score difference: -1.9244485135487892\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: -2.1738540974039644\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -2.534763936260454\n",
            "Dropped feature: Combined in-family sentences (LaBSE) | Score difference: -2.8475637580025968\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: -3.113730680884963\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -3.22421194282796\n",
            "\n",
            "\n",
            "LaBSE ECOND-HM ablation experiment\n",
            "Dropped feature: Combined in-family sentences (LaBSE) | Score difference: 0.05063046779669611\n",
            "Dropped feature: Combined sentences (LaBSE) | Score difference: 0.024817862287948897\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.013061189424213152\n",
            "Dropped feature: Same Genus? | Score difference: 7.79825257350708e-06\n",
            "Dropped feature: Same Word Order? | Score difference: -0.00010921185526750754\n",
            "Dropped feature: Combined in-genus sentences (LaBSE) | Score difference: -0.00022050860585579035\n",
            "Dropped feature: Same Family? | Score difference: -0.00043902324188749287\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.0005549923298013015\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: -0.0006484675761729564\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: -0.005292842536381986\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: -0.008499506025806527\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.041923091467889875\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: -0.0543895933454894\n",
            "\n",
            "\n",
            "LaBSE avg. margin score ablation experiment\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.07679985887940755\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: 0.034876410633977506\n",
            "Dropped feature: Combined sentences (LaBSE) | Score difference: 0.024301586963855176\n",
            "Dropped feature: Combined in-family sentences (LaBSE) | Score difference: 0.007719308465425179\n",
            "Dropped feature: Same Genus? | Score difference: -1.3773338356448672e-05\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: -8.434771939935803e-05\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.0007721091921477075\n",
            "Dropped feature: Same Family? | Score difference: -0.001094174462460018\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: -0.0018141949070326624\n",
            "Dropped feature: Combined in-genus sentences (LaBSE) | Score difference: -0.0018694720877838744\n",
            "Dropped feature: Same Word Order? | Score difference: -0.0031653663381369657\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: -0.003227684390767427\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.01814723784528116\n",
            "\n",
            "\n",
            "LASER F1-score ablation experiment\n",
            "Dropped feature: Combined in-family sentences (LASER) | Score difference: 0.03532655308145333\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: 0.034090201192904346\n",
            "Dropped feature: Same Word Order? | Score difference: 0.014845703435949376\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: 0.009062735090504759\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.006155983489184336\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: 0.0016916191473048126\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: 0.001103256677490616\n",
            "Dropped feature: Same Family? | Score difference: 0.000568760502462462\n",
            "Dropped feature: Combined in-genus sentences (LASER) | Score difference: 0.00015885817914013112\n",
            "Dropped feature: Same Genus? | Score difference: -0.0007391347953327743\n",
            "Dropped feature: Combined sentences (LASER) | Score difference: -0.000841200574562273\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.0025014959703905104\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.006197126425025512\n",
            "\n",
            "\n",
            "LASER GH dist. ablation experiment\n",
            "Dropped feature: Combined in-family sentences (LASER) | Score difference: 0.01170852720237383\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.011516445324771418\n",
            "Dropped feature: Same Word Order? | Score difference: 0.010489577791007787\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: 0.002804860489116035\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: 0.0027856004947055205\n",
            "Dropped feature: Combined sentences (LASER) | Score difference: 6.921745205095125e-05\n",
            "Dropped feature: Same Genus? | Score difference: 1.4123918417818793e-05\n",
            "Dropped feature: Combined in-genus sentences (LASER) | Score difference: -0.0006598227178345791\n",
            "Dropped feature: Same Family? | Score difference: -0.0021272974244777917\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.003883400899434042\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: -0.004149404810619562\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.007408686284347976\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: -0.010804680206020845\n",
            "\n",
            "\n",
            "LASER SVG ablation experiment\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: 0.12210076492366895\n",
            "Dropped feature: Same Word Order? | Score difference: 0.045996229455272264\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: 0.024431252872374465\n",
            "Dropped feature: Same Genus? | Score difference: 0.0006070374917470645\n",
            "Dropped feature: Combined sentences (LASER) | Score difference: -0.0012463497644237265\n",
            "Dropped feature: Combined in-genus sentences (LASER) | Score difference: -0.025368497825972725\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: -0.0494573144482775\n",
            "Dropped feature: Same Family? | Score difference: -0.068461744711942\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: -0.1629783877770743\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: -0.16455936176583563\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.32840567146623023\n",
            "Dropped feature: Combined in-family sentences (LASER) | Score difference: -0.4006159427286615\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.5136894728137866\n",
            "\n",
            "\n",
            "LASER ECOND-HM ablation experiment\n",
            "Dropped feature: Combined in-family sentences (LASER) | Score difference: 0.05376929029901581\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.04303776283631127\n",
            "Dropped feature: Combined sentences (LASER) | Score difference: 0.018473247825301464\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: 0.01436651882626154\n",
            "Dropped feature: Same Family? | Score difference: 0.009733927772574924\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: 0.0023229796708655326\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: -0.00048052019916516864\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: -0.0005638277784352774\n",
            "Dropped feature: Same Genus? | Score difference: -0.0007712784773083181\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.0011656812150869916\n",
            "Dropped feature: Combined in-genus sentences (LASER) | Score difference: -0.0013382095941681382\n",
            "Dropped feature: Same Word Order? | Score difference: -0.004028024792243651\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: -0.016029288917307788\n",
            "\n",
            "\n",
            "LASER avg. margin score ablation experiment\n",
            "Dropped feature: Combined sentences (LASER) | Score difference: 0.030704686799008576\n",
            "Dropped feature: Combined in-family sentences (LASER) | Score difference: 0.028208706676016784\n",
            "Dropped feature: Same Polysynthesis Status? | Score difference: 0.0015596997047992028\n",
            "Dropped feature: Same Word Order? | Score difference: 0.0013753483275052783\n",
            "Dropped feature: Character-level Overlap (multiset Jaccard coefficient, Book of Matthew) | Score difference: 0.0013201462157613336\n",
            "Dropped feature: Geographic Distance (lang2vec) | Score difference: 0.0008338622100955949\n",
            "Dropped feature: Syntactic Distance (lang2vec) | Score difference: 0.0007432489929740799\n",
            "Dropped feature: Combined in-genus sentences (LASER) | Score difference: 7.327060421214587e-06\n",
            "Dropped feature: Same Genus? | Score difference: -0.0015927878852523975\n",
            "Dropped feature: Same Family? | Score difference: -0.0026651532178667003\n",
            "Dropped feature: Phonological Distance (lang2vec) | Score difference: -0.015857708281955263\n",
            "Dropped feature: Token-level Overlap (multiset Jaccard coefficient, Book of John) | Score difference: -0.019002520856765303\n",
            "Dropped feature: Inventory Distance (lang2vec) | Score difference: -0.05307703403547537\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrfF_uaS3FyG"
      },
      "source": [
        "# Let's see how important each feature is, on average, according to the ablation experiments\n",
        "\n",
        "# LaBSE\n",
        "feature_orders_in_ablation_labse = {}\n",
        "for idx, item in enumerate(labse_f1_ablation.keys()):\n",
        "  feature_orders_in_ablation_labse[item] = [idx]\n",
        "for idx, item in enumerate(labse_gh_ablation.keys()):\n",
        "  feature_orders_in_ablation_labse[item].append(idx)\n",
        "for idx, item in enumerate(labse_svg_ablation.keys()):\n",
        "  feature_orders_in_ablation_labse[item].append(idx)\n",
        "for idx, item in enumerate(labse_econdhm_ablation.keys()):\n",
        "  feature_orders_in_ablation_labse[item].append(idx)\n",
        "for idx, item in enumerate(labse_avgmarg_ablation.keys()):\n",
        "  feature_orders_in_ablation_labse[item].append(idx)\n",
        "\n",
        "for k in feature_orders_in_ablation_labse: \n",
        "  feature_orders_in_ablation_labse[k] = np.average(feature_orders_in_ablation_labse[k])\n",
        "\n",
        "# LASER\n",
        "feature_orders_in_ablation_laser = {}\n",
        "for idx, item in enumerate(laser_f1_ablation.keys()):\n",
        "  feature_orders_in_ablation_laser[item] = [idx]\n",
        "for idx, item in enumerate(laser_gh_ablation.keys()):\n",
        "  feature_orders_in_ablation_laser[item].append(idx)\n",
        "for idx, item in enumerate(laser_svg_ablation.keys()):\n",
        "  feature_orders_in_ablation_laser[item].append(idx)\n",
        "for idx, item in enumerate(laser_econdhm_ablation.keys()):\n",
        "  feature_orders_in_ablation_laser[item].append(idx)\n",
        "for idx, item in enumerate(laser_avgmarg_ablation.keys()):\n",
        "  feature_orders_in_ablation_laser[item].append(idx)\n",
        "\n",
        "for k in feature_orders_in_ablation_laser: \n",
        "  feature_orders_in_ablation_laser[k] = np.average(feature_orders_in_ablation_laser[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ms9Emom9UUe"
      },
      "source": [
        "# Sort the average feature order lists\n",
        "feature_orders_in_ablation_labse = sorted(feature_orders_in_ablation_labse.items(), key=lambda item: item[1])\n",
        "feature_orders_in_ablation_laser = sorted(feature_orders_in_ablation_laser.items(), key=lambda item: item[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPSdvZMt-oEG",
        "outputId": "eb06db8c-a21f-4acf-8eee-d69efe37ce69"
      },
      "source": [
        "feature_orders_in_ablation_labse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Same Polysynthesis Status?', 2.4),\n",
              " ('Combined sentences (LaBSE)', 2.4),\n",
              " ('Combined in-family sentences (LaBSE)', 3.6),\n",
              " ('Same Genus?', 3.8),\n",
              " ('Geographic Distance (lang2vec)', 4.0),\n",
              " ('Token-level Overlap (multiset Jaccard coefficient, Book of John)', 5.0),\n",
              " ('Same Family?', 6.0),\n",
              " ('Same Word Order?', 6.2),\n",
              " ('Combined in-genus sentences (LaBSE)', 6.8),\n",
              " ('Phonological Distance (lang2vec)', 7.8),\n",
              " ('Inventory Distance (lang2vec)', 9.2),\n",
              " ('Syntactic Distance (lang2vec)', 10.4),\n",
              " ('Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)',\n",
              "  10.4)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H8qS-zc_gxO",
        "outputId": "38cd8813-3c68-4a05-f6f9-5461a15b7ae0"
      },
      "source": [
        "feature_orders_in_ablation_laser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Combined in-family sentences (LASER)', 2.4),\n",
              " ('Same Polysynthesis Status?', 3.4),\n",
              " ('Same Word Order?', 3.8),\n",
              " ('Geographic Distance (lang2vec)', 4.0),\n",
              " ('Combined sentences (LASER)', 4.2),\n",
              " ('Token-level Overlap (multiset Jaccard coefficient, Book of John)', 5.8),\n",
              " ('Syntactic Distance (lang2vec)', 6.4),\n",
              " ('Same Genus?', 6.8),\n",
              " ('Same Family?', 7.0),\n",
              " ('Phonological Distance (lang2vec)', 7.4),\n",
              " ('Combined in-genus sentences (LASER)', 7.4),\n",
              " ('Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)',\n",
              "  8.8),\n",
              " ('Inventory Distance (lang2vec)', 10.6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qITMCOZBiH1o"
      },
      "source": [
        "Taking a look at the loadings of the first principal components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH7Zf61a_ho2"
      },
      "source": [
        "pca = sklearn.decomposition.PCA(n_components=7)\n",
        "X_pair_labse_pca = pca.fit_transform(X_pair_labse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "9iynCpsEjigL",
        "outputId": "870220b4-2db5-4e5b-d12d-edef05872787"
      },
      "source": [
        "pca_labse_loadings = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7'], index=X_pair_labse.columns)\n",
        "pca_labse_loadings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "      <th>PC6</th>\n",
              "      <th>PC7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Combined sentences (LaBSE)</th>\n",
              "      <td>2.502606e-02</td>\n",
              "      <td>-2.302449e-01</td>\n",
              "      <td>9.728109e-01</td>\n",
              "      <td>-8.594273e-11</td>\n",
              "      <td>1.117763e-11</td>\n",
              "      <td>6.886880e-11</td>\n",
              "      <td>8.956845e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-family sentences (LaBSE)</th>\n",
              "      <td>9.781237e-01</td>\n",
              "      <td>2.066641e-01</td>\n",
              "      <td>2.375051e-02</td>\n",
              "      <td>-2.114363e-11</td>\n",
              "      <td>2.833677e-12</td>\n",
              "      <td>-1.760387e-11</td>\n",
              "      <td>9.550099e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-genus sentences (LaBSE)</th>\n",
              "      <td>2.065135e-01</td>\n",
              "      <td>-9.509349e-01</td>\n",
              "      <td>-2.303800e-01</td>\n",
              "      <td>-5.917627e-12</td>\n",
              "      <td>1.149760e-11</td>\n",
              "      <td>-2.852874e-11</td>\n",
              "      <td>-4.499855e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Family?</th>\n",
              "      <td>2.442863e-11</td>\n",
              "      <td>-1.186291e-12</td>\n",
              "      <td>-2.558616e-11</td>\n",
              "      <td>1.665598e-01</td>\n",
              "      <td>-6.072729e-04</td>\n",
              "      <td>8.815682e-01</td>\n",
              "      <td>-2.185311e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Genus?</th>\n",
              "      <td>3.641867e-12</td>\n",
              "      <td>-1.481723e-11</td>\n",
              "      <td>-1.808615e-11</td>\n",
              "      <td>7.376720e-02</td>\n",
              "      <td>1.449742e-02</td>\n",
              "      <td>3.422799e-01</td>\n",
              "      <td>3.476761e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)</th>\n",
              "      <td>2.533685e-12</td>\n",
              "      <td>-2.338400e-11</td>\n",
              "      <td>-1.015035e-10</td>\n",
              "      <td>4.927664e-02</td>\n",
              "      <td>2.707725e-02</td>\n",
              "      <td>1.699503e-01</td>\n",
              "      <td>9.648707e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Token-level Overlap (multiset Jaccard coefficient, Book of John)</th>\n",
              "      <td>6.676305e-12</td>\n",
              "      <td>-1.419060e-11</td>\n",
              "      <td>-1.200290e-11</td>\n",
              "      <td>6.231845e-02</td>\n",
              "      <td>-1.869166e-02</td>\n",
              "      <td>5.808725e-02</td>\n",
              "      <td>1.139495e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Word Order?</th>\n",
              "      <td>1.098025e-11</td>\n",
              "      <td>-5.379153e-12</td>\n",
              "      <td>7.589818e-11</td>\n",
              "      <td>7.604240e-01</td>\n",
              "      <td>6.168356e-01</td>\n",
              "      <td>-1.740229e-01</td>\n",
              "      <td>-3.477787e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Polysynthesis Status?</th>\n",
              "      <td>1.566873e-11</td>\n",
              "      <td>-2.214384e-11</td>\n",
              "      <td>6.687281e-11</td>\n",
              "      <td>6.023378e-01</td>\n",
              "      <td>-7.806668e-01</td>\n",
              "      <td>-1.237408e-01</td>\n",
              "      <td>3.427196e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geographic Distance (lang2vec)</th>\n",
              "      <td>-4.276751e-12</td>\n",
              "      <td>6.738397e-13</td>\n",
              "      <td>-7.912971e-13</td>\n",
              "      <td>-6.414253e-02</td>\n",
              "      <td>6.452793e-02</td>\n",
              "      <td>-4.583518e-02</td>\n",
              "      <td>-1.126186e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Syntactic Distance (lang2vec)</th>\n",
              "      <td>-7.479314e-12</td>\n",
              "      <td>6.142650e-12</td>\n",
              "      <td>1.531741e-11</td>\n",
              "      <td>-9.848203e-02</td>\n",
              "      <td>-6.252564e-02</td>\n",
              "      <td>-1.311390e-01</td>\n",
              "      <td>-6.613712e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phonological Distance (lang2vec)</th>\n",
              "      <td>-5.804170e-12</td>\n",
              "      <td>-3.282547e-12</td>\n",
              "      <td>2.869235e-11</td>\n",
              "      <td>-5.810592e-02</td>\n",
              "      <td>2.200306e-02</td>\n",
              "      <td>-7.048143e-02</td>\n",
              "      <td>1.253858e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inventory Distance (lang2vec)</th>\n",
              "      <td>-8.393670e-13</td>\n",
              "      <td>-3.526877e-12</td>\n",
              "      <td>1.639753e-11</td>\n",
              "      <td>-4.753500e-02</td>\n",
              "      <td>1.492307e-02</td>\n",
              "      <td>-5.969127e-02</td>\n",
              "      <td>-7.517913e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             PC1  ...           PC7\n",
              "Combined sentences (LaBSE)                          2.502606e-02  ...  8.956845e-11\n",
              "Combined in-family sentences (LaBSE)                9.781237e-01  ...  9.550099e-12\n",
              "Combined in-genus sentences (LaBSE)                 2.065135e-01  ... -4.499855e-11\n",
              "Same Family?                                        2.442863e-11  ... -2.185311e-01\n",
              "Same Genus?                                         3.641867e-12  ...  3.476761e-02\n",
              "Character-level Overlap (multiset Jaccard coeff...  2.533685e-12  ...  9.648707e-01\n",
              "Token-level Overlap (multiset Jaccard coefficie...  6.676305e-12  ...  1.139495e-01\n",
              "Same Word Order?                                    1.098025e-11  ... -3.477787e-02\n",
              "Same Polysynthesis Status?                          1.566873e-11  ...  3.427196e-03\n",
              "Geographic Distance (lang2vec)                     -4.276751e-12  ... -1.126186e-03\n",
              "Syntactic Distance (lang2vec)                      -7.479314e-12  ... -6.613712e-03\n",
              "Phonological Distance (lang2vec)                   -5.804170e-12  ...  1.253858e-02\n",
              "Inventory Distance (lang2vec)                      -8.393670e-13  ... -7.517913e-02\n",
              "\n",
              "[13 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "k0-3a5efj4nV",
        "outputId": "1d8c299f-fd5d-41d0-ad13-83402bf54bd4"
      },
      "source": [
        "pca = sklearn.decomposition.PCA(n_components=6)\n",
        "X_pair_laser_pca = pca.fit_transform(X_pair_laser)\n",
        "\n",
        "pca_laser_loadings = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'], index=X_pair_laser.columns)\n",
        "pca_laser_loadings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "      <th>PC6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Combined sentences (LASER)</th>\n",
              "      <td>5.278870e-02</td>\n",
              "      <td>2.534754e-01</td>\n",
              "      <td>9.659004e-01</td>\n",
              "      <td>-7.829993e-10</td>\n",
              "      <td>-5.931677e-10</td>\n",
              "      <td>2.270194e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-family sentences (LASER)</th>\n",
              "      <td>9.595111e-01</td>\n",
              "      <td>-2.808669e-01</td>\n",
              "      <td>2.126670e-02</td>\n",
              "      <td>-8.332706e-10</td>\n",
              "      <td>-5.561003e-12</td>\n",
              "      <td>-5.781421e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combined in-genus sentences (LASER)</th>\n",
              "      <td>2.766801e-01</td>\n",
              "      <td>9.256695e-01</td>\n",
              "      <td>-2.580391e-01</td>\n",
              "      <td>4.331148e-10</td>\n",
              "      <td>4.398405e-10</td>\n",
              "      <td>-2.723431e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Family?</th>\n",
              "      <td>6.970970e-10</td>\n",
              "      <td>-1.283782e-10</td>\n",
              "      <td>-4.763840e-11</td>\n",
              "      <td>1.844851e-01</td>\n",
              "      <td>-1.106274e-02</td>\n",
              "      <td>8.905448e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Genus?</th>\n",
              "      <td>1.097854e-10</td>\n",
              "      <td>1.194304e-10</td>\n",
              "      <td>-7.064345e-11</td>\n",
              "      <td>7.713173e-02</td>\n",
              "      <td>1.648315e-02</td>\n",
              "      <td>3.313864e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Character-level Overlap (multiset Jaccard coefficient, Book of Matthew)</th>\n",
              "      <td>1.715241e-10</td>\n",
              "      <td>3.677290e-10</td>\n",
              "      <td>-8.567859e-11</td>\n",
              "      <td>2.393325e-02</td>\n",
              "      <td>3.626291e-02</td>\n",
              "      <td>1.175703e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Token-level Overlap (multiset Jaccard coefficient, Book of John)</th>\n",
              "      <td>2.069948e-10</td>\n",
              "      <td>2.673701e-11</td>\n",
              "      <td>6.424421e-12</td>\n",
              "      <td>6.482068e-02</td>\n",
              "      <td>-1.774875e-02</td>\n",
              "      <td>5.757673e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Word Order?</th>\n",
              "      <td>3.417722e-10</td>\n",
              "      <td>-4.965815e-10</td>\n",
              "      <td>1.150795e-09</td>\n",
              "      <td>7.134407e-01</td>\n",
              "      <td>6.728537e-01</td>\n",
              "      <td>-1.679619e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Same Polysynthesis Status?</th>\n",
              "      <td>4.299693e-10</td>\n",
              "      <td>-8.016002e-11</td>\n",
              "      <td>1.109024e-10</td>\n",
              "      <td>6.539579e-01</td>\n",
              "      <td>-7.325129e-01</td>\n",
              "      <td>-1.512901e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geographic Distance (lang2vec)</th>\n",
              "      <td>-1.289039e-10</td>\n",
              "      <td>4.584065e-11</td>\n",
              "      <td>-5.536855e-11</td>\n",
              "      <td>-6.769655e-02</td>\n",
              "      <td>6.196094e-02</td>\n",
              "      <td>-4.332774e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Syntactic Distance (lang2vec)</th>\n",
              "      <td>-2.360005e-10</td>\n",
              "      <td>1.018701e-10</td>\n",
              "      <td>-2.228513e-11</td>\n",
              "      <td>-9.332465e-02</td>\n",
              "      <td>-6.478047e-02</td>\n",
              "      <td>-1.311319e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phonological Distance (lang2vec)</th>\n",
              "      <td>-1.702423e-10</td>\n",
              "      <td>1.490600e-10</td>\n",
              "      <td>-9.037521e-12</td>\n",
              "      <td>-5.705214e-02</td>\n",
              "      <td>2.193978e-02</td>\n",
              "      <td>-7.933177e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inventory Distance (lang2vec)</th>\n",
              "      <td>-2.121742e-11</td>\n",
              "      <td>1.049058e-10</td>\n",
              "      <td>-3.899056e-11</td>\n",
              "      <td>-4.511767e-02</td>\n",
              "      <td>1.231904e-02</td>\n",
              "      <td>-5.923524e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             PC1  ...           PC6\n",
              "Combined sentences (LASER)                          5.278870e-02  ...  2.270194e-10\n",
              "Combined in-family sentences (LASER)                9.595111e-01  ... -5.781421e-10\n",
              "Combined in-genus sentences (LASER)                 2.766801e-01  ... -2.723431e-10\n",
              "Same Family?                                        6.970970e-10  ...  8.905448e-01\n",
              "Same Genus?                                         1.097854e-10  ...  3.313864e-01\n",
              "Character-level Overlap (multiset Jaccard coeff...  1.715241e-10  ...  1.175703e-01\n",
              "Token-level Overlap (multiset Jaccard coefficie...  2.069948e-10  ...  5.757673e-02\n",
              "Same Word Order?                                    3.417722e-10  ... -1.679619e-01\n",
              "Same Polysynthesis Status?                          4.299693e-10  ... -1.512901e-01\n",
              "Geographic Distance (lang2vec)                     -1.289039e-10  ... -4.332774e-02\n",
              "Syntactic Distance (lang2vec)                      -2.360005e-10  ... -1.311319e-01\n",
              "Phonological Distance (lang2vec)                   -1.702423e-10  ... -7.933177e-02\n",
              "Inventory Distance (lang2vec)                      -2.121742e-11  ... -5.923524e-02\n",
              "\n",
              "[13 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRKDfS4d34Dy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}